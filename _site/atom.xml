<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Taotao's Zone</title>
  <meta name="baidu-site-verification" content="6b2f48c1baf35f9e0eb29b4455265203"/>
  <meta name="baidu-site-verification" content="hgXDOPtWLn" />
  <meta name="google-site-verification" content="YqjJD80rZQfugWoznvslaHlII_viwiMiUDEEgPTLEDw" />
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <script src="/files/dc3da690b0d2a5655a8d6150862a2a07.html"></script>
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile-min.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.min.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
  <!-- growingIO code -->
  <!-- 去除 growingIO 统计，功能不全，也没 cnzz 和 ga 好用，还耗时 -->
<!--   <script type='text/javascript'>
      var _vds = _vds || [];
      window._vds = _vds;
      (function(){
        _vds.push(['setAccountId', '9f3f34627219ccd1']);
        (function() {
          var vds = document.createElement('script');
          vds.type='text/javascript';
          vds.async = true;
          vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
          var s = document.getElementsByTagName('script')[0];
          s.parentNode.insertBefore(vds, s);
        })();
      })();
  </script> -->
  <!-- baidu spider initiative push -->
  <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
  </script>
  <!-- google analytics push code -->
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72176628-2', 'auto');
      ga('send', 'pageview');
  </script>

</head>

<!-- meiqia plug-in -->
<!-- 
<script type='text/javascript'>
    (function(m, ei, q, i, a, j, s) {
        m[a] = m[a] || function() {
            (m[a].a = m[a].a || []).push(arguments)
        };
        j = ei.createElement(q),
            s = ei.getElementsByTagName(q)[0];
        j.async = true;
        j.charset = 'UTF-8';
        j.src = i + '?v=' + new Date().getUTCDate();
        s.parentNode.insertBefore(j, s);
    })(window, document, 'script', '//static.meiqia.com/dist/meiqia.js', '_MEIQIA');
    _MEIQIA('entId', 15857);
</script>
 -->
<body>
  <?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

   <title>Taotao's Zone</title>
   <link href="http://litaotao.github.io/atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://litaotao.github.io" rel="alternate" type="text/html" />
   <updated>2016-05-14T11:30:16+08:00</updated>
   <id>http://litaotao.github.io</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>如何使用 github pages 搭建博客</title>
     <link href="/github-pages-blog"/>
     <updated>2016-05-10T00:00:00+08:00</updated>
     <id>/github-pages-blog</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;使用 github 也快有3年了，的确觉得 github 的方便，易用，而且不仅仅在版本控制方面［版本控制方面个人感觉比 svn 好用了太多太多］，而且还提供了一个平台，让你随时跟进最近技术和趋势。今天就来说说其中一个比较实用&lt;/p&gt;

&lt;p&gt;ps: 本文对应的 github repo 在这里：&lt;a href=&quot;https://github.com/litaotao/github-blog-template&quot;&gt;https://github.com/litaotao/github-blog-template&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 最简单的步骤&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;step 1 : 新建一个 repo，并克隆 repo 到本地&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;repo 名定为 你的github用户名 + .github.io，比如说，我的 github 用户名叫 &lt;code class=&quot;highlighter-rouge&quot;&gt;litaotao&lt;/code&gt;, 那新建的 repo 名就叫 &lt;code class=&quot;highlighter-rouge&quot;&gt;litaotao.github.io&lt;/code&gt;&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;step 2 : 克隆&lt;a href=&quot;https://github.com/litaotao/github-blog-template&quot;&gt;模版&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-1.png&quot; alt=&quot;github-pages-blog-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用 git 命令克隆模版：&lt;em&gt;git clone git@github.com:litaotao/github-blog-template.git&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/tmp&lt;span class=&quot;nv&quot;&gt;$git&lt;/span&gt; clone git@github.com:litaotao/github-blog-template.git
Cloning into &lt;span class=&quot;s1&quot;&gt;&#39;github-blog-template&#39;&lt;/span&gt;...
remote: Counting objects: 75, &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;.
remote: Compressing objects: 100% &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;68/68&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;.
remote: Total 75 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;delta 4&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, reused 72 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;delta 4&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, pack-reused 0
Receiving objects: 100% &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;75/75&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, 1.19 MiB | 425.00 KiB/s, &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;.
Resolving deltas: 100% &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;4/4&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;.
Checking connectivity... &lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;step 3 : 复制模版相关文件到你的本地repo中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先，先删掉模版里的一个文件夹 &lt;code class=&quot;highlighter-rouge&quot;&gt;.git&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/tmp/github-blog-template&lt;span class=&quot;nv&quot;&gt;$ll&lt;/span&gt;
...
...
...
drwxr-xr-x  13 taotao  staff   442B May 10 10:32 .git
taotao@mac007:~/Desktop/tmp/github-blog-template&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; rm -rf .git&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;然后，复制模版下所有文件到你的本地repo中，使用命令 &lt;em&gt;cp -r github-blog-template/&lt;/em&gt; your_local_repo/*&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;taotao&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@mac007&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Desktop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blog&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;your_local_repo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;step 4 : 本地运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;进入到 your_local_repo 目录，使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll server --watch&lt;/code&gt; 命令启动本地博客。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/tmp/your_local_repo&lt;span class=&quot;nv&quot;&gt;$jekyll&lt;/span&gt; server --watch
Configuration file: /Users/chenshan/Desktop/tmp/your_local_repo/_config.yml
            Source: /Users/chenshan/Desktop/tmp/your_local_repo
       Destination: /Users/chenshan/Desktop/tmp/your_local_repo/_site
 Incremental build: disabled. Enable with --incremental
      Generating...
                    &lt;span class=&quot;k&quot;&gt;done in &lt;/span&gt;0.588 seconds.
 Auto-regeneration: enabled &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;/Users/chenshan/Desktop/tmp/your_local_repo&#39;&lt;/span&gt;
Configuration file: /Users/chenshan/Desktop/tmp/your_local_repo/_config.yml
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;如果一切顺利，在浏览器访问：localhost:4000 即可看到你的博客了，我已经在模版里放了两篇文章，截图如下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-2.png&quot; alt=&quot;github-pages-blog-2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 自定义配置&lt;/h2&gt;

&lt;p&gt;如果你已经成功完成了第一步，那恭喜，你马上就能拥有一个自己的博客了，在此之前，你只需要改一个配置文件即可：github-blog-template/_config.yml，你需要改的地方我用中文标注出来了，可以参考注释说明和我的博客来配置：&lt;a href=&quot;https://github.com/litaotao/litaotao.github.io&quot;&gt;https://github.com/litaotao/litaotao.github.io&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;markdown: kramdown
highlighter: rouge
paginate: 8
permalink: /:title
encoding: UTF-8
gems: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;jekyll-paginate]

title: 你的博客名称
url: 你的博客地址，就叫 http://github用户名+.github.io
feed: /atom.xml
author_info: &amp;lt;a &lt;span class=&quot;nv&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://litaotao.github.io/&quot;&lt;/span&gt;&amp;gt;你的名字&amp;lt;/a&amp;gt;

myblog:
  gavatar: 你的头像地址
  gpname: 你的名字
  linkedin: 你的 linkedin 地址
  github: 你的 github 地址
  email: mailto:你的 email 地址
  coverimgs: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;
  postbgimg: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;

categories: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;你的博客目录名称，对应到 your_local_repo/_posts/ 下的文件夹名]&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;ok,如果你已经更改好配置文件了，并且本地运行正常的话，可以上传到 github 了。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 深度阅读之目录文件说明&lt;/h2&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/github/github-blog-template&lt;span class=&quot;nv&quot;&gt;$tree&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 404 页面，你可以自定义&lt;/span&gt;
├── 404.html
├── README.md
&lt;span class=&quot;c&quot;&gt;### 博客配置文件，基本上是最重要的一个文件之一了&lt;/span&gt;
├── _config.yml
&lt;span class=&quot;c&quot;&gt;### 博客页面模版目录&lt;/span&gt;
├── _layouts
│   ├── default.html
│   ├── home.html
│   ├── page.html
│   └── post.html
&lt;span class=&quot;c&quot;&gt;### 博客文章目录，下面可以按文件夹进行博文分类&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 注意，博文文件格式必须是：时间-博文标题.md，参考下面的格式&lt;/span&gt;
├── _posts
│   ├── books
│   │   └── 2016-04-29-books-recommend-and-summarize-on-apr-2016.md
│   └── python
│       └── 2016-04-01-spark-in-finance-and-investing.md
&lt;span class=&quot;c&quot;&gt;### 这个是你的站点地图了，用户可以访问这个文件夹下面的所有文件&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 比如说，用户可以直接访问我的 litaotao.github.io/404.html; litaotao.github.io/images/2.jpg&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 比如说，当你访问 litaotao.github.io/spark-in-finance-and-investing  &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;###        实际上是访问了 litaotao.github.io/spark-in-finance-and-investing.html&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 你会发现这下面有很多在博客更目录下重复的文件夹，比如说 css，js，images等文件夹，不要纳闷，这是正常的&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 因为你的博客更目录下的文件，是 jekyll 用来渲染一个 html 文件的，html 文件及其所需要的任何文件，都会放到 _site 这个&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 专用的目录下面&lt;/span&gt;
├── _site
│   ├── 404.html
│   ├── README.md
│   ├── atom.xml
│   ├── books-recommend-and-summarize-on-apr-2016.html
│   ├── css
│   │   ...
│   │   ...
│   │   ...
│   ├── images
│   │   ├── 2.jpg
│   │   ├── spark-in-finance-1.jpg
│   │   ├── spark-in-finance-2.jpg
│   │   └── spark-in-finance-3.jpg
│   ├── index.html
│   ├── js
│   │   ...
│   │   ...
│   │   ...
│   └── spark-in-finance-and-investing.html
├── atom.xml
├── css
│   │   ...
│   │   ...
│   │   ...
├── images
│   │   ...
│   │   ...
│   │   ...
├── index.html
└── js
    │   │   ...
    │   ...
    │   ...&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4. 总结&lt;/h2&gt;

&lt;p&gt;总的来说，利用 github 搭建博客的步骤为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;创建一个 github用户名 + ‘.github.io’ 的新 repo，并克隆到本地&lt;/li&gt;
  &lt;li&gt;把模版，除去 ‘.git’ 的所有文件 copy 到你的repo 中&lt;/li&gt;
  &lt;li&gt;更改 ‘_config.yml’ 配置文件&lt;/li&gt;
  &lt;li&gt;本地试运行，上传到github&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5. 其他话题&lt;/h2&gt;

&lt;p&gt;一个简单，但基本够用的博客就这样搭建完成了。其他还有一些扩展话题，感兴趣的同学可以 google 或者联系我，比如说：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何给你的博客加上 评论功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-3.png&quot; alt=&quot;github-pages-blog-3.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何给你的博客加上 cnzz 统计功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-4.png&quot; alt=&quot;github-pages-blog-4.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何给你的博客加上 growingio 统计功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-5.png&quot; alt=&quot;github-pages-blog-5.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何给你的博客加上 百度分享功能&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/github-pages-blog-6.png&quot; alt=&quot;github-pages-blog-6.png&quot; /&gt;&lt;/p&gt;
</content>
   </entry>
   
   <entry>
     <title>一封素不相识的来信</title>
     <link href="/words-to-share-with-the-young"/>
     <updated>2016-05-09T00:00:00+08:00</updated>
     <id>/words-to-share-with-the-young</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;前几天无意间收到一封email，是一位小学弟写的，看到这封信，我仿佛看到大学时期的自己。从大一开始就没消停过，一开始捣鼓航模，还想趁军训期间和同学倒卖医用纱布，面膜，防嗮霜什么的；后来大二开始学习电路后，又开始捣鼓单片机，嵌入式，arduino，电路设计；大三后想出国又去整托福雅思，再后来发现没法拿到全额奖学金后；大四就开始乖乖找工作，学驾照，做毕业设计，最后大四下学期就来上海开始在第一家［也是现在的这家］公司实习。&lt;/p&gt;

&lt;p&gt;回首大学时期，期间真的遇到过无数蛋疼的事情，也不断的在各个迷茫的漩涡中 back and forth。但是现在，在毕业2年后，我却觉得就像一句台词说的那样：当回首过去，才知道那些当时看起来的坎坎坷坷其实没也多大不了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;I always knew looking back on the tears would make me laugh.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;我本想认真的回复他，可是想想，也许现实中还有很多像他一样的学弟学妹，也正面临各种艰难的抉择和迷茫的漩涡。如果我把给他的回复放到博客上，只要其他的小学弟学妹也能看到，岂不最大化这封 email 的价值？［sorry，在金融业浸淫两年有余，做什么事都容易把价值最大化，投入产出比这些 f**king awesome factors 考虑进去］&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这是那位学弟的来信［已征求学弟同意，允许发布到博客上］&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/words-to-the-young-1.png&quot; alt=&quot;words-to-the-young-1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-key-problems&quot;&gt;1. The Key Problems&lt;/h2&gt;

&lt;p&gt;下面，是我根据这封 email 的内容和我的个人经验，总结的一些这位学弟面临的问题。到最后，我会一一再次回答学弟信里提到的几个问题。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How should I schedule my time when I want to broaden my horizens?&lt;/li&gt;
  &lt;li&gt;When I want to learning something new, there always be endless materials to read!&lt;/li&gt;
  &lt;li&gt;How to build a web page to record your daily routines or growth plan?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;about-schedule-time&quot;&gt;2. About Schedule Time&lt;/h2&gt;

&lt;p&gt;关于怎么合理安排时间，这是一个比较大的话题，但是在生活中能时时遇到，我觉得这个问题没有一个可以量化的答案，但是可以有一个准则：优先考虑最重要的事，尽量顾及不重要的事，给突发急事优先处理权。&lt;/p&gt;

&lt;p&gt;举个例子，如果你想做一个技术型管理者，可以给自己制定了这样一个发展路线：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在自己擅长的技术方面，做到这个技术领域的高手，比如说 python，后台开发框架，分布式架构设计&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;这是你知识的深度；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;在管理能力培养方面，多多看书，听相关讲座和分享，多跟老人交流分享&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;这是你知识的广度；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当你已经开始熟悉一个领域，并且想对其他方面有所了解的时候；即当你在某些方面有一些深度了解，又想扩宽自己的知识面的时候。你应该怎么安排你的时间呢？在我看来，或者以我的个人经历来看，我很推荐二八原则，即可以把 20% 的时间花在其他方面上，并且严格控制好限度，千万不可以为一昧想看其他方面的东西而影响当前一些工作和正常学习的进度。&lt;/p&gt;

&lt;h2 id=&quot;about-endless-materials&quot;&gt;3. About Endless Materials&lt;/h2&gt;

&lt;p&gt;这个话题是一个比较好玩的话题，不知道大家有没有这样一个感受，从小学到大学，成绩最好的那些同学，真的不是做作业做得最多的那些同学。同样的，一个公司里最能干的人，很少是那些加班加到天昏地暗的人。我一直对这种现象很好奇，知道最近几年开始慢慢带小孩儿［侄儿］，开始有去想如何教育孩子的经验之后，我才慢慢理解这种现象：在这种学习，工作的社会活动中，你投入的量越多，并不一定能带来质的提升。&lt;/p&gt;

&lt;p&gt;简单的说，你所进行的学习，工作，需要你投入脑力和体力这两大核心要素，而在很多时候，我们发现一些同学去做了很多练习册，也发现一些同事无休止的加班，其实这些都是投入了大量体力的劳动，但是，其中的大部分人在这个体力活动的过程中，却很少去进行思考：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这道题为什么会错？&lt;/li&gt;
  &lt;li&gt;我在第一次接触这道题的时候是怎么去思考的？&lt;/li&gt;
  &lt;li&gt;下一次遇到这种题，切入点，思考点应该是什么？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也就是说，有些情况下，即使你投入了大量的体力，但却很少动用脑力去思考，反思的话，很难会有质的提升。言归正传，之所以要扯上面这些，我是想强调一个概念：你找的资料越多，看得越多，并不一定能让你懂得越多。&lt;/p&gt;

&lt;p&gt;所以，当你想学一个新事物的时候，面临那么多纷繁的资料，你怎么办？我觉得，如果你找了10份资料，那就简单看下，从其中先选出你觉得最好的2～3份资料，然后 completely delete 其他落选的资料，把你分配的 20% 时间全部花在选出来的这 2～3 份资料上面。看完之后，你一定会知道你对那个新的学科，新的领域了解多少，你也会知道如果你还想深入下去，你还需要哪些东西需要学习，有的放矢。&lt;/p&gt;

&lt;h2 id=&quot;about-blogs-for-personal-use&quot;&gt;4. About Blogs for Personal Use&lt;/h2&gt;

&lt;p&gt;这里的可选项很多，但我觉得基于 github pages 的博客比较方便，简洁，灵活。这个网上有很多教程，只需要 google 一下 ： &lt;a href=&quot;https://www.google.co.jp/webhp?sourceid=chrome-instant&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=github+blog+pages&quot;&gt;github blog pages&lt;/a&gt; 就行了，我这里也专门有一个简单教程和模版：&lt;a href=&quot;../github-pages-blog&quot;&gt;如何使用 github pages 搭建博客&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;除了博客，我强烈推荐使用 google docs 来做一些短期规划和跟踪，我之前有用过很多协同工具来做计划任务的安排，比如说有道云协作，evernote，但它们对我来说都太过于复杂了，还是觉得 google docs 好用。&lt;/p&gt;

&lt;p&gt;对于使用工具来制定，记录和跟踪你的短期安排，长期规划，我有一个小建议，不管用什么工具，一定要明确工具就是工具，不要把太多的时间花在工具上面，否则就本末倒置了。&lt;/p&gt;

&lt;p&gt;下面是我一些 google docs 的截图：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每月读书规划和记录［当月下旬最后几天会根据当月读书情况完成下月的读书计划］&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/words-to-the-young-2.png&quot; alt=&quot;words-to-the-young-2.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每月安排，出于公司隐私考虑，这里面有删掉了一些工作内容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/words-to-the-young-3.png&quot; alt=&quot;words-to-the-young-3.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;5. 小步总结&lt;/h2&gt;

&lt;p&gt;其实，上面回答了三个方面的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如何规划时间&lt;/li&gt;
  &lt;li&gt;如何学习一门新技能&lt;/li&gt;
  &lt;li&gt;如何利用工具制定，跟踪个人计划&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个方面都没有往深了说，但我觉得能表达到意思就够了，如果觉得有问题的可以直接留言或通过其他方式联系我，可以一起探讨。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;6. 一一回答信中的问题&lt;/h2&gt;

&lt;p&gt;下面一一回答信中的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;你是怎麼分配時間同時學習幾個領域的知識？我本科的電腦課都讀完了，但當我嘗試進入machine learning/ data mining/ AI 的領域時，發現自己並不能專心致志的向一個方向閱讀／練習，反而是在網上能找到的資料太多，看的眼花凌亂，學習並沒有效率。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;我一般在想学习其他领域的时候，我会根据当前工作，生活安排情况，最多安排出 20% 的时间，在短期内把这 20% 的时间全部用到那个新领域上去。之后再根据对该领域的了解和自身职业发展，兴趣爱好情况，对这个领域的安排做调整。
例子：在团度 4月的团建上，我发现自己还是很喜欢台球，于是安排了这个月的 5% 左右的时间在台球学习和整理上，之后会把相关资料放到博客上，或者你也可以先到 github 上看：&lt;a href=&quot;https://github.com/litaotao/litaotao.github.io/blob/master/_posts/work/2016-04-29-pools-and-billiards.md&quot;&gt;2016-04-29-pools-and-billiards&lt;/a&gt;&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;你的讀書筆記網站是怎麼設置／日常是怎麼使用的？我在設想一個放到github.pages，有著簡單版面的博客／ 紀錄系統兩用網站。我本來是一個比較back-end focused的人，除了一步一步找javascript教學我現在沒有足夠的經驗去設計一個複雜的網站。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;如果你想有一个博客来制定，安排，跟踪你的学习规划，现学 html，js，css 是完全不够的，而且是本末倒置的。All you need is just a tool other than building the tool. 我一般都使用 google docs 和 基于 github pages 搭建的博客，教程在这里：&lt;a href=&quot;../github-pages-blog&quot;&gt;如何使用 github pages 搭建博客&lt;/a&gt; ，你可以看这个教程页面了解更多。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;對於看書／行業以外的知識，你是怎麼控制的？我常常一不小心就開出幾十個tab，然後每個tab又有幾十個有用的延伸閱讀材料，根本不能夠完成目標。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;就像我在第一个问题里面回复的一样：首先，我会想清楚除了 &lt;code class=&quot;highlighter-rouge&quot;&gt;主营业务&lt;/code&gt; 之外，我最想做什么。第二，我会去单独找一份资料，并且深度学习那份资料去了解这个我想学习的东西。例子：我5月份想系统学习台球知识，网上的台球教程有很多，当然也很有可能一下子开十几个 tab 页面出来。我的做法是，我找一个微信公众号［我找的是 &lt;code class=&quot;highlighter-rouge&quot;&gt;taiqiujiaoxue&lt;/code&gt; 这个公众号］，把这个公众号里的文章全部看完［截至5月13号，我大概看了这个公众号上 2.5 年的文章］。
相信我，千万不要一开始就找很多资料，去找1～3份不错的资料，然后深度研读他们，读完你会知道，针对于那个领域，你还需要了解什么。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;我看到了你對金融也有興趣／研究，對於學習fin tech的技術跟行業知識，你有一些提議嗎？&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;fin-tech 其实定义很广泛，我也不知道你具体想学哪个细分领域的知识。fin-tech 是 financial 和 technology 的结合，也是最近几年才兴起的概念，特别是伴随大数据的兴起，最近一两年股市的跌宕起伏，fin-tech 也开始一波强势宣传。但是，万变不离其宗，简单的说，fin－tech 就是金融 ＋ 互联网。如果你想学习这方面的知识，我可以从 fin-tech 的一个方面［量化投资］给你一些建议和我的一些经验：第一，学习掌握基本的金融概念和知识；第二，了解一些互联网行业从业知识；第三，使用相关网站［uqer.io, quantopian.com, www.worldquant.com 等］；第四，关注这个行业的业内新闻，紧跟发展节奏。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;words-to-share-with-you&quot;&gt;7. Words to share with you&lt;/h2&gt;

&lt;p&gt;这封回信也差不多写完了，作为结尾，我想说，其实每个人的见解都有其局限性，所以对比自己有经验的人的意见和建议，都需要先对比自身情况，选择性接收。&lt;/p&gt;

&lt;p&gt;但是，有一些话，有一些哲理却是更古不变的，所以，作为结尾，我想以几句话和各位一起分享，你们可以不同意我上面所说的任何话，但是对下面的几句话，keeping them in mind is a much wiser choice:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I always knew looking back on the tears would make me laugh;&lt;/li&gt;
  &lt;li&gt;You are what you’ve done in the past, what you’re doing tells what you will be tomorrow;&lt;/li&gt;
  &lt;li&gt;Be the top 20% in your field;&lt;/li&gt;
  &lt;li&gt;Keep 20/80 principle in your mind;&lt;/li&gt;
  &lt;li&gt;Something reasonable in your eyes is unbelievable to others;&lt;/li&gt;
  &lt;li&gt;A thing turns into its opposite if pushed too far;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，祝大家：&lt;em&gt;Love what you do, do what you love.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/words-to-the-young-4.png&quot; alt=&quot;words-to-the-young-4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;8. 参考文档&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;In Startups And Life, You Need Plan A, B, And Z&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh/%E5%B8%95%E9%9B%B7%E6%89%98%E6%B3%95%E5%88%99&quot;&gt;帕雷托法则&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Spark 』10. spark 应用程序性能优化｜12 个优化方法</title>
     <link href="/boost-spark-application-performance"/>
     <updated>2016-05-03T00:00:00+08:00</updated>
     <id>/boost-spark-application-performance</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;why-how-when-what&quot;&gt;1. 优化? Why? How? When? What?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/how_when_what_why.jpg&quot; alt=&quot;how_when_what_why.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“spark 应用程序也需要优化？”，很多人可能会有这个疑问，“不是已经有代码生成器，执行优化器，pipeline 什么的了的吗？”。是的，spark 的确是有一些列强大的内置工具，让你的代码在执行时更快。但是，如果一切都依赖于工具，框架来做的话，我想那只能说明两个问题：1. 你对这个框架仅仅是知其然，而非知其所以然；2. 看来你也只是照葫芦画瓢而已，没了你，别人也可以轻轻松松的写这样一个 spark 应用程序，so you are replaceable;&lt;/p&gt;

&lt;p&gt;在做 spark 应用程序的优化的时候，从下面几个点出发就够了：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;为什么：因为你的资源有限，因为你的应用上生产环境了会有很多不稳定的因素，在上生产前做好优化和测试是唯一一个降低不稳定因素影响的办法；&lt;/li&gt;
  &lt;li&gt;怎么做：web ui ＋ log 是做优化的倚天剑和屠龙刀，能掌握好这两点就可以了；&lt;/li&gt;
  &lt;li&gt;何时做：应用开发成熟时，满足业务要求时，就可以根据需求和时间安排开始做了；&lt;/li&gt;
  &lt;li&gt;做什么：一般来说，spark 应用程序 80% 的优化，都是集中在三个地方：内存，磁盘io，网络io。再细点说，就是 driver，executor 的内存，shuffle 的设置，文件系统的配置，集群的搭建，集群和文件系统的搭建［e.g 尽量让文件系统和集群都在一个局域网内，网络更快；如果可以，可以让 driver 和 集群也在一个局域网内，因为有时候需要从 worker 返回数据到 driver］&lt;/li&gt;
  &lt;li&gt;备注：千万不要一心想着优化都从程序本身入手，虽然大多数时候都是程序自己的原因，但在入手检查程序之前最好先确认所有的 worker 机器情况都正常哦。比如说机器负载，网络情况。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面这张图来自 databricks 的一个分享 &lt;a href=&quot;https://www.youtube.com/watch?v=kkOG_aJ9KjQ&quot;&gt;Tuning and Debugging Apache Spark&lt;/a&gt;，很有意思，说得非常对啊，哈哈。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-5.png&quot; alt=&quot;spark-optimization-5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OK，下面我们来看看一些常见的优化方法。&lt;/p&gt;

&lt;h2 id=&quot;repartition-and-coalesce&quot;&gt;2. repartition and coalesce&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/ch04.html&quot;&gt;原文：&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Spark provides the `repartition()` function, which shuffles the data 
across the network to create a new set of partitions. Keep in mind 
that repartitioning your data is a fairly expensive operation. Spark 
also has an optimized version of `repartition()` called `coalesce()` 
that allows avoiding data movement, but only if you are decreasing 
the number of RDD partitions. To know whether you can safely call 
coalesce(), you can check the size of the RDD using `rdd.partitions.size()` 
in Java/Scala and `rdd.getNumPartitions()` in Python and make sure 
that you are coalescing it to fewer partitions than it currently has.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;总结：当要对 rdd 进行重新分片时，如果目标片区数量小于当前片区数量，那么用 &lt;code class=&quot;highlighter-rouge&quot;&gt;coalesce&lt;/code&gt;，不要用 &lt;code class=&quot;highlighter-rouge&quot;&gt;repartition&lt;/code&gt;。关于 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt; 的更多优化细节，参考 &lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/ch04.html&quot;&gt;chapter 4 of Learning Spark&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;passing-functions-to-spark&quot;&gt;3. Passing Functions to Spark&lt;/h2&gt;

&lt;p&gt;In Python, we have three options for passing functions into Spark.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;lambda expressions&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;error&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;top-level functions&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;my_personal_lib&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_personal_lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containsError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;locally defined functions&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;containsError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;error&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containsError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;One issue to watch out for when passing functions is inadvertently serializing the object containing the function. When you pass a function that is the member of an object, or contains references to fields in an object (e.g., self.field), Spark sends the entire object to worker nodes, which can be much larger than the bit of information you need. Sometimes this can also cause your program to fail, if your class contains objects that Python can’t figure out how to pickle.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### wrong way&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SearchFunctions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isMatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getMatchesFunctionReference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# Problem: references all of &quot;self&quot; in &quot;self.isMatch&quot;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isMatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getMatchesMemberReference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# Problem: references all of &quot;self&quot; in &quot;self.query&quot;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### the right way&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;WordFunctions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getMatchesNoReference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# Safe: extract only the field we need into a local variable&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;worker-cpu-memroy-executors&quot;&gt;4. worker 的资源分配：cpu, memroy, executors&lt;/h2&gt;

&lt;p&gt;这个话题比较深，而且在不同的部署模式也不一样 [standalone, yarn, mesos]，这里给不了什么建议。唯一的一个宗旨是，不要一昧考虑把所有资源都独立给到 spark 来用，要考虑到机器本身的一些进程，spark 依赖的一些进程，网络情况，任务情况 [计算密集，IO密集，long-live task]等。&lt;/p&gt;

&lt;p&gt;这里只能推荐一些 video，slide 和 blog，具体情况具体分析，以后我遇到资源调优的时候再把实际案例发出来。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=WyfHUNnMutg&quot;&gt;Top 5 Mistakes When Writing Spark Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;shuffle-block-size-limitation&quot;&gt;5. shuffle block size limitation&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;No Spark shuffle block can be greater than 2 GB&lt;/em&gt; — spark shuffle 里的 block size 不能大于 &lt;em&gt;2g&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-1.png&quot; alt=&quot;spark-optimization-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Spark 使用一个叫 &lt;em&gt;ByteBuffer&lt;/em&gt; 的数据结构来作为 shuffle 数据的缓存，但这个 &lt;em&gt;ByteBuffer&lt;/em&gt; 默认分配的内存是 2g，所以一旦 shuffle 的数据超过 2g 的时候，shuflle 过程会出错。影响 shuffle 数据大小的因素有以下常见的几个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;partition 的数量，partition 越多，分布到每个 partition 上的数据越少，越不容易导致 shuffle 数据过大;&lt;/li&gt;
  &lt;li&gt;数据分布不均匀，一般是 &lt;em&gt;groupByKey&lt;/em&gt; 后，存在某几个 key 包含的数据过大，导致该 key 所在的 partition 上数据过大，有可能触发后期 shuflle block 大于 2g;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一般解决这类办法都是增加 partition 的数量，&lt;a href=&quot;https://www.youtube.com/watch?v=WyfHUNnMutg&quot;&gt;Top 5 Mistakes When Writing Spark Applications&lt;/a&gt; 这里说可以预计让每个 partition 上的数据为 128MB 左右，仅供参考，还是需要具体场景具体分析，这里只把原理讲清楚就行了，并没有一个完美的规范。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sc.textfile 时指定一个比较大的 partition number&lt;/li&gt;
  &lt;li&gt;spark.sql.shuffle.partitions&lt;/li&gt;
  &lt;li&gt;rdd.repartition&lt;/li&gt;
  &lt;li&gt;rdd.coalesce&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TIPS&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;在 partition 小于 2000 和大于 2000 的两种场景下，Spark 使用不同的数据结构来在 shuffle 时记录相关信息，在 partition 大于 2000 时，会有另一种更高效 [压缩] 的数据结构来存储信息。所以如果你的 partition 没到 2000，但是很接近 2000，可以放心的把 partition 设置为 2000 以上。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BlockManagerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uncompressedSizes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MapStatus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uncompressedSizes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;HighlyCompressedMapStatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uncompressedSizes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CompressedMapStatus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uncompressedSizes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;level-of-parallel--partition&quot;&gt;6. level of parallel － partition&lt;/h2&gt;

&lt;p&gt;先来看看一个 stage 里所有 task 运行的一些性能指标，其中的一些说明：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scheduler Delay&lt;/code&gt;: spark 分配 task 所花费的时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Executor Computing Time&lt;/code&gt;: executor 执行 task 所花费的时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Getting Result Time&lt;/code&gt;: 获取 task 执行结果所花费的时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Result Serialization Time&lt;/code&gt;: task 执行结果序列化时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Task Deserialization Time&lt;/code&gt;: task 反序列化时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Write Time&lt;/code&gt;: shuffle 写数据时间&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Read Time&lt;/code&gt;: shuffle 读数据所花费时间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-7.png&quot; alt=&quot;spark-optimization-7.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而这里要说的 &lt;code class=&quot;highlighter-rouge&quot;&gt;level of parallel&lt;/code&gt;，其实大多数情况下都是指 partition 的数量，partition 数量的变化会影响上面几个指标的变动。我们调优的时候，很多时候都会看上面的指标变化情况。当 partition 变化的时候，上面几个指标变动情况如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;partition 过小［容易引入 data skew 问题］
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scheduler Delay&lt;/code&gt;: 无明显变化&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Executor Computing Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Getting Result Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Result Serialization Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Task Deserialization Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Write Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Read Time&lt;/code&gt;: 不稳定，有大有小，但平均下来比较大&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;partition 过大
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Scheduler Delay&lt;/code&gt;: 无明显变化&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Executor Computing Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Getting Result Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Result Serialization Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Task Deserialization Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Write Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Read Time&lt;/code&gt;: 比较稳定，平均下来比较小&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那应该怎么设置 partition 的数量呢？这里同样也没有专门的公式和规范，一般都在尝试几次后有一个比较优化的结果。但宗旨是：尽量不要导致 data skew 问题，尽量让每一个 task 执行的时间在一段变化不大的区间之内。&lt;/p&gt;

&lt;h2 id=&quot;data-skew&quot;&gt;7. data skew&lt;/h2&gt;

&lt;p&gt;大多数时候，我们希望的分布式计算带来的好处应该是像下图这样的效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-2.png&quot; alt=&quot;spark-optimization-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是，有时候，却是下面这种效果，这就是所谓的 data skew。即数据没有被 &lt;code class=&quot;highlighter-rouge&quot;&gt;大致均匀&lt;/code&gt; 的分布到集群中，这样对一个 task 来说，整个 task 的执行时间取决于第一个数据块被处理的时间。在很多分布式系统中，data skew 都是一个很大的问题，比如说分布式缓存，假设有 10 台缓存机器，但有 50% 的数据都落到其中一台机器上，那么当这台机器 down 掉之后，整个缓存的数据就会丢掉一般，缓存命中率至少 [肯定大于] 降低 50%。这也是很多分布式缓存中要引入一致性哈希，要引入 &lt;code class=&quot;highlighter-rouge&quot;&gt;虚拟节点 vnode&lt;/code&gt; 的原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-3.png&quot; alt=&quot;spark-optimization-3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一致性哈希原理图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/consistent_hashing_003.jpg&quot; alt=&quot;consistent_hashing_003.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;回到正题，在 spark 中如何解决 data skew 的问题？首先明确这个问题的发生场景和根源：一般来说，都是 (key, value) 型数据中，key 的分布不均匀，这种场景比较常见的方法是把 key 进行 salt 处理 [不知道 salt 中文应该怎么说]，比如说原来有 2 个 key (key1, key2)，并且 key1 对应的数据集很大，而 key2 对应的数据集相对较小，可以把 key 扩张成多个 key (key1-1, key1-2, …, key1-n, key2-1, key2-2, …, key2-m) ，并且保证 &lt;code class=&quot;highlighter-rouge&quot;&gt;key1-*&lt;/code&gt; 对应的数据都是原始 &lt;code class=&quot;highlighter-rouge&quot;&gt;key1&lt;/code&gt; 对应的数据集上划分而来的，&lt;code class=&quot;highlighter-rouge&quot;&gt;key2-*&lt;/code&gt; 上对应的数据都是原始的 &lt;code class=&quot;highlighter-rouge&quot;&gt;key2&lt;/code&gt; 对应的数据集上划分而来。这样之后，我们有 &lt;code class=&quot;highlighter-rouge&quot;&gt;m+n&lt;/code&gt; 个 key，而且每个 key 对应的数据集都相对较小，并行度增加，每个并行程序处理的数据集大小差别不大，可以大大提速并行处理效率。在这两个个分享里都有提到这种方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=WyfHUNnMutg&quot;&gt;Top 5 Mistakes When Writing Spark Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8hn2KVC8FvA&amp;amp;index=6&amp;amp;list=PL-x35fyliRwiuc6qy9z2erka2VX8LY53x&quot;&gt;Sparkling: Speculative Partition of Data for Spark Applications - Peilong Li&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;avoid-cartesian-operation&quot;&gt;8. avoid cartesian operation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cartesian&quot;&gt;rdd.cartesian&lt;/a&gt; 操作很耗时，特别是当数据集很大的时候，cartesian 的数量级都是平方级增长的，既耗时也耗空间。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cartesian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;avoid-shuffle-when-possible&quot;&gt;9. avoid shuffle when possible&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-6.png&quot; alt=&quot;spark-optimization-6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;spark 中的 shuffle 默认是把上一个 stage 的数据写到 disk 上，然后下一个 stage 再从 disk 上读取数据。这里的磁盘 IO 会对性能造成很大的影响，特别是数据量大的时候。&lt;/p&gt;

&lt;h2 id=&quot;use-reducebykey-instead-of-groupbykey-when-possible&quot;&gt;10. use reduceByKey instead of GroupByKey when possible&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-9.png&quot; alt=&quot;spark-optimization-9.png&quot; /&gt;
&lt;img src=&quot;../images/spark-optimization-10.png&quot; alt=&quot;spark-optimization-10.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;use-treereduce-instead-of-reduce-when-possible&quot;&gt;11. use treeReduce instead of reduce when possible&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-optimization-4.png&quot; alt=&quot;spark-optimization-4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;use-kryo-serializer&quot;&gt;12. use Kryo serializer&lt;/h2&gt;

&lt;p&gt;spark 应用程序中，在对 RDD 进行 shuffle 和 cache 时，数据都是需要被序列化才可以存储的，此时除了 IO 外，数据序列化也可能是应用程序的瓶颈。这里推荐使用 kryo 序列库，在数据序列化时能保证较高的序列化效率。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.serializer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.serializer.KryoSerializer&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;next&quot;&gt;13. Next&lt;/h2&gt;

&lt;p&gt;这些都是一些实际实践中的经验和对一些高质量分享的总结［大多数是来自那些高质量分享］，里面可能有说得不完全正确的地方，在未来亲自实践，调试过后会再有一篇性能调试的 blog 的，本篇仅供参考哦。下一次，我们来看看怎么统一部署和配置 spark 的 cluster，那的确几乎来自个人实践经验了。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;14. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/ch04.html&quot;&gt;chapter 4 of Learning Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/ch08.html&quot;&gt;chapter 8 of Learning Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=WyfHUNnMutg&quot;&gt;Top 5 Mistakes When Writing Spark Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gitbook.com/book/databricks/databricks-spark-knowledge-base/details&quot;&gt;Databricks Spark Knowledge Base&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8hn2KVC8FvA&amp;amp;index=6&amp;amp;list=PL-x35fyliRwiuc6qy9z2erka2VX8LY53x&quot;&gt;Sparkling: Speculative Partition of Data for Spark Applications - Peilong Li&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://datarus.wordpress.com/2015/05/04/fighting-the-skew-in-spark/&quot;&gt;Fighting the skew in Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kkOG_aJ9KjQ&quot;&gt;Tuning and Debugging Apache Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/tuning.html#level-of-parallelism&quot;&gt;Tuning Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/best_practices/prefer_reducebykey_over_groupbykey.html&quot;&gt;Avoid GroupByKey&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 读书笔记 』4月读书总结｜博文推荐</title>
     <link href="/books-recommend-and-summarize-on-apr-2016"/>
     <updated>2016-04-29T00:00:00+08:00</updated>
     <id>/books-recommend-and-summarize-on-apr-2016</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;计划是每月读 5-10 本书，书籍类型大概是三个方面的：金融，技术，管理。之所以选择这三个方面，一方面是因为自己对这三个方面都很有兴趣，其次是被 linkedin 创始人 Hoffman 的 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;ABZ 理论&lt;/a&gt; 深度影响。建议大家都看看 abz 理论那篇文章，如果我有空，也会整理一些常用的这类理论模型到博客里的。&lt;/p&gt;

&lt;p&gt;月底读书总结的形式都很简单，只是简单的一个列表和简单的书评，对觉得比较好的书会有单独的读书笔记。另外推荐大家用 excel 来做一些简单的工作管理，我现在就用 google docs 来做工作安排和读书计划，个人感觉比一些常用的神马协同软件强大太多了，简单，够用，就行了。工作中见过太多人把时间都花到使用那些协同软件上去，不得不说避重就轻了，适得其反，哈哈。&lt;/p&gt;

&lt;p&gt;下面是一张我用 google docs 来做本月读书安排的截图，不同颜色代表不同类别的数据，清晰明了实用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/book-reading-04.png&quot; alt=&quot;book-reading-04.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本月看了 11 本书，其中第十本是一些研报的合集，就当是一本了；第十一本是 coursera 上的一门公开课 &lt;em&gt;Successful Negotiation: Essential Strategies and Skills&lt;/em&gt;，也当是一本书了。其中有电子书版的都放到亲爱的&lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;度娘云&lt;/a&gt;里了，个人觉得不错的书都是纸板的，不知道有没有电子版的，推荐好书都看纸版的。&lt;/p&gt;

&lt;p&gt;ps: 我对好书的定义很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给自己有所启发的&lt;/li&gt;
  &lt;li&gt;高质量的，专业的教程类书籍&lt;/li&gt;
  &lt;li&gt;后期会再度回首的书&lt;/li&gt;
  &lt;li&gt;看完后会打算赠送给盆友看的书&lt;/li&gt;
  &lt;li&gt;留着给儿子看的书 [好吧，目前我只有个宝贝侄儿，哈哈]&lt;/li&gt;
  &lt;li&gt;最后一条，印刷质量要好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上月读书总结：&lt;a href=&quot;../books-recommend-and-summarize-on-mar-2016&quot;&gt;『 读书笔记 』3月读书总结和推荐&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 读书总结&lt;/h2&gt;

&lt;h3 id=&quot;learning-sparkhttpswwwamazoncne5ada6e4b9a0spark-e58da1e58ab3dpb016ofnu9mrefsr11ieutf8qid1460795691sr8-1keywordslearningspark&quot;&gt;1.1 &lt;a href=&quot;https://www.amazon.cn/%E5%AD%A6%E4%B9%A0Spark-%E5%8D%A1%E5%8A%B3/dp/B016OFNU9M/ref=sr_1_1?ie=UTF8&amp;amp;qid=1460795691&amp;amp;sr=8-1&amp;amp;keywords=learning+spark&quot;&gt;Learning Spark&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是 spark 几个作者一起写的第一本系统性介绍 spark 的书籍，质量非常高，内容非常赞，强烈推荐对 spark 感兴趣的人读，即使在 spark 方面有很多经验的高手也可以看看。我个人非常喜欢这本书，我自己是在 &lt;a href=&quot;https://www.safaribooksonline.com/library/view/learning-spark/9781449359034/&quot;&gt;safaribooksonline&lt;/a&gt; 上看的，体验非常好。虽然这本书出版时间较久，2015年初出版的，里面肯定会介绍不到 spark 之后的一些特性，但是我依然强烈推荐。只要多读几遍这本书，把里面的知识点都掌握好了，对 spark 后来的特性掌握完全不是问题。&lt;/p&gt;

&lt;p&gt;总结：这是我读过的最好的技术书籍之一。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httppanbaiducoms1borig5t&quot;&gt;1.2 &lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;程序员跳槽全攻略&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;哈哈，这本书不知道是在哪个地方看到的。当时觉得很惊奇，难道连跳槽都还要有攻略？说实话，现在已经想不起来这本书讲了什么了。或许对我来说没什么用吧，我一直觉得找工作，换工作这类事都是一个水到渠成的问题。只要你真的准备好了，一切都有可能。就跟做项目管理一样，有的人一心想怎么提高员工的积极性，一心去找什么协同软件，项目软件来管理项目，我觉得这却是本末倒置了。时间要花在刀刃上，问题不要治标不治本。就项目管理这个事来说，我强烈推荐 西蒙·斯涅克 的这个 TED talk：&lt;a href=&quot;https://www.youtube.com/watch?v=u4ZoJKF_VuA&quot;&gt;Start with why – how great leaders inspire action&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;总结：如果你希望看攻略来获得 &lt;em&gt;自我提升&lt;/em&gt;，完全没必要看这本书；不过也可以花些闲暇时光来读这本书，不要带有任何目的性。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne5a4a7e59e8be7bd91e7ab99e68a80e69cafe69eb6e69e84-e6a0b8e5bf83e58e9fe79086e4b88ee6a188e4be8be58886e69e90-e69d8ee699bae685a7dpb00f3z26g8refsr11ieutf8qid1461222402sr8-1keywordse5a4a7e59e8be7bd91e7ab99e68a80e69cafe69eb6e69e84&quot;&gt;1.3 &lt;a href=&quot;https://www.amazon.cn/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84-%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E4%B8%8E%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-%E6%9D%8E%E6%99%BA%E6%85%A7/dp/B00F3Z26G8/ref=sr_1_1?ie=UTF8&amp;amp;qid=1461222402&amp;amp;sr=8-1&amp;amp;keywords=%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84&quot;&gt;大型网站技术架构:核心原理与案例分析&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书写得还可以，虽然只有 200 多页，原理也讲得很浅，很多细节问题都没有深入去探究，甚至还专门花一章讲了自己的一个项目，略有点铺张浪费大意思。但是，这本书对于没有亲历过大型网站架构，但对这方面有兴趣的同学来说，还是能有所启发的，至少能有一个框架在脑子里。就跟注音版的百科全书一样，虽然不能方方面面都讲解到，但是能让小孩儿对这个世界有一个形象的认识。&lt;/p&gt;

&lt;p&gt;总结：对新手来说，可以了解大型网站的技术架构框架；对老手来说，也许可以偶尔花个下午茶时间随手翻翻。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;apachesparkanalyticsmadesimplehttpsdatabrickscomblog20160331introducing-our-new-ebook-apache-spark-analytics-made-simplehtml&quot;&gt;1.4 &lt;a href=&quot;https://databricks.com/blog/2016/03/31/introducing-our-new-ebook-apache-spark-analytics-made-simple.html&quot;&gt;Apache_Spark_Analytics_Made_Simple&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是 databricks 出的一本电子书，其实是收录了 databricks 上几篇比较好的 blog。不得不再说一次，databricks 真的是我见过的最会做 marketing 的技术类公司了，summit，meetup，blog，news，linkedin 上经常都是他们的信息。这次简单把 blog 上几篇比较不错的几篇文章合成一本电子书，又宣传了一把，虽然说是换汤不换药，但是确实有效。好了，回归主题，这本电子书里的文章都能在 databricks blog 上看到，其中有几篇他们都在 summit，meetup 上提到过，内容上的确不错，但如果你看过很多他们的 summit 和 blog 的话，可以不用再重复看这本电子书了。&lt;/p&gt;

&lt;p&gt;总结：撇开新壶装旧酒不说，这本书里的内容还是很不错的，如果没看过blog，没看过 summit，可以看看。推荐指数全 5 星，因为参杂了个人主观因素，哈哈，我自己很喜欢 databricks 出的东西。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-redis-official-documenthttppanbaiducoms1borig5t&quot;&gt;1.5 &lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;spark-redis official document&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;之所以看官方这个文档，是因为一篇博文 &lt;a href=&quot;http://www.infoq.com/cn/articles/spark-processing-efficiency&quot;&gt;45倍加速Spark的处理效率？&lt;/a&gt;，当时还挺惊讶的，于是乎想了解了解 spark ＋ redis 会擦出什么样的火花。官方有两个文档，都挺简短的，在上面的链接里可以看到［感谢度娘，明明可以靠脸蛋儿］。总的来说，就是 redis 官方开发了一个 spark 的第三方包 &lt;a href=&quot;http://spark-packages.org/package/RedisLabs/spark-redis&quot;&gt;spark-redis&lt;/a&gt;，支持 rdd 从 redis 里读取数据。that’s all。但是我看完文档后并不是很感冒，因为文档里的例子就一个，而且我并没有觉得 spark 里有特别需要从 redis 里读取数据的需求，实在需要，为什么不把数据 cache 到内存呢？为何还要走 redis 这条路，路越长越容易出错呀。而且，还有一个很大的问题是，既然用到了 spark，那么数据量一般都不会小，那么如果采用 spark ＋ redis 的方案，是不是要考虑到 redis 扩容，容错的问题呢？那是不是要一个 redis cluster 呢？这个 redis cluster 是不是要和 spark cluster 在一起呢？如果在一起会不会互相有所影响呢？如果不在一起网络 IO 会不会让你情不自禁地说 fuck 呢？最重要的是，老板会问你是不是又要烧他的钱买机器了呢？&lt;/p&gt;

&lt;p&gt;总结：个人目前觉得必要性不大，但是，可以去了解。&lt;em&gt;见识&lt;/em&gt; 这东西，虽然有了不一定能了不起，但没有的话就很难了不起了，哈哈。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne585ace58fb8e8b4a2e58aa1e58e9fe79086-e79086e69fa5e5beb7-a-e5b883e99bb7e588a9dpb006z2yi32refsr12ieutf8qid1461250263sr8-2keywordse585ace58fb8e8b4a2e58aa1e58e9fe79086&quot;&gt;1.6 &lt;a href=&quot;https://www.amazon.cn/%E5%85%AC%E5%8F%B8%E8%B4%A2%E5%8A%A1%E5%8E%9F%E7%90%86-%E7%90%86%E6%9F%A5%E5%BE%B7-A-%E5%B8%83%E9%9B%B7%E5%88%A9/dp/B006Z2YI32/ref=sr_1_2?ie=UTF8&amp;amp;qid=1461250263&amp;amp;sr=8-2&amp;amp;keywords=%E5%85%AC%E5%8F%B8%E8%B4%A2%E5%8A%A1%E5%8E%9F%E7%90%86&quot;&gt;公司财务原理（第十版），第一，二章&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书是今年以来我看到的最好的一本公司财务相关的书，推荐看第十版英文原版的，之前有看过几章第八版中文版的，但我觉得原版的看起来似乎比中文版更易懂。推荐看英文原版，遇到问题和不理解的地方可以参考中文版来促进理解。&lt;em&gt;公司财务原理&lt;/em&gt; 和上个月读的 &lt;em&gt;估值的艺术&lt;/em&gt;，是我觉得非常非常好的两本关于公司财务和发展，金融基础的书。当初想系统的看一些这类书最初是因为想在自己的量化策略里加上一些基本面的因子和指标，后来看了 &lt;em&gt;估值的艺术&lt;/em&gt; 和 &lt;em&gt;公司财务原理&lt;/em&gt; 前两章下来，我觉得这两本书对自己以后创业帮助极大，它能告诉你从哪些方面来跟踪公司的发展情况，以及制定财务计划，了解公司运作，金融市场运作流程等，极有用。这也是我特地降低这本书的看书速度的原因，因为是英文原版，而且内容很丰富，所以我打算这本书每个月看2章到3章就行了，关键是要真正理解。&lt;/p&gt;

&lt;p&gt;总结：从小来说，这本书能让你了解公司财务，金融市场运作的一些情况，对从事投资方面的人来说很有用；从大来说，这本书能交给你不少关于如何开展，运作一个公司的很多规则和经验，非常有用。严重推荐，值得认真研读。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne98791e5ad97e5a194e58e9fe79086-e9baa6e882afe994a140e5b9b4e7bb8fe585b8e59fb9e8aeade69599e69d90-e88aade88aade68b89-e6988ee68998dpb00g33nkp0refsr11ieutf8qid1461466347sr8-1keywordse98791e5ad97e5a194e58e9fe79086&quot;&gt;1.7 &lt;a href=&quot;https://www.amazon.cn/%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86-%E9%BA%A6%E8%82%AF%E9%94%A140%E5%B9%B4%E7%BB%8F%E5%85%B8%E5%9F%B9%E8%AE%AD%E6%95%99%E6%9D%90-%E8%8A%AD%E8%8A%AD%E6%8B%89-%E6%98%8E%E6%89%98/dp/B00G33NKP0/ref=sr_1_1?ie=UTF8&amp;amp;qid=1461466347&amp;amp;sr=8-1&amp;amp;keywords=%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86&quot;&gt;金字塔原理&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书真正吸引我的是它的副标题：&lt;em&gt;思考，表达和解决问题的逻辑&lt;/em&gt;。通看下来，前面3章比较有用，介绍了所谓的 &lt;em&gt;金字塔原理&lt;/em&gt; 是个什么原理，但是后面的介绍过于细致了，有时候容易让读者迷失在那些细节之中。而且这本书读下来有一种干涩的感觉，有点像教科书。我不太确定是不是因为中文翻译的问题，过段时间可能会再看看原版的，到时候再回来说明一下。&lt;/p&gt;

&lt;p&gt;总结：&lt;em&gt;思考，表达和解决问题的逻辑&lt;/em&gt;，这个副标题很吸引我，但与其花很多时间通读本书，还不如细读两边前3章。也许是中文翻译的问题，文字比较干涩无力，读完原版的后再回来写点总结。anyway，还是很推荐这本书的前3章的。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-hitchhikers-guide-to-pythonhttpdocspython-guideorgenlatest&quot;&gt;1.8 &lt;a href=&quot;http://docs.python-guide.org/en/latest/&quot;&gt;The Hitchhiker’s Guide to Python!&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是 python 界一位大神，也是 &lt;em&gt;requests&lt;/em&gt; 包的作者，kennethreitz 写的一本入门教程。读这本书完全是佩服 kennethreitz，想看看这些有足够实战经验的大神写出来的书是什么样的。内容还算丰富，开发工具和相关 package 就列出了一大堆，应该都是大神了解过的。里面也解答了一些我一直以来的疑问，推荐新手和老手都看看，不会花很多时间，但肯定会有或多或少的收获，性价比挺高。&lt;/p&gt;

&lt;p&gt;总结：具有很多实战经验的大神写的书，不管是新手还是老手都值得看一下。虽然不会解决你所有的问题［当然不会，有哪本书能解决你所有的问题哦～］，但是肯定会有所收获。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne5889be4b89ae7bbb4e889b0-e5a682e4bd95e5ae8ce68890e6af94e99abee69bb4e99abee79a84e4ba8b-e69cace280a2e99c8de6b49be7bbb4e88ca8dpb00smb8zvurefsr11ieutf8qid1461653303sr8-1keywordse5889be4b89ae7bbb4e889b0&quot;&gt;1.9 &lt;a href=&quot;https://www.amazon.cn/%E5%88%9B%E4%B8%9A%E7%BB%B4%E8%89%B0-%E5%A6%82%E4%BD%95%E5%AE%8C%E6%88%90%E6%AF%94%E9%9A%BE%E6%9B%B4%E9%9A%BE%E7%9A%84%E4%BA%8B-%E6%9C%AC%E2%80%A2%E9%9C%8D%E6%B4%9B%E7%BB%B4%E8%8C%A8/dp/B00SMB8ZVU/ref=sr_1_1?ie=UTF8&amp;amp;qid=1461653303&amp;amp;sr=8-1&amp;amp;keywords=%E5%88%9B%E4%B8%9A%E7%BB%B4%E8%89%B0&quot;&gt;创业维艰&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书真正吸引我的，是它的英文原标题：&lt;em&gt;the hard thing about hard things&lt;/em&gt;。很有趣，这个英文标题一下子就吸引我了，而且公司大 boss 也推荐过，遂前两天从公司图书馆借来看了下，准备回头自己也买一本。［我有个习惯，想看的书，一般都会先在公司图书馆借来看看，有感觉再买］。事实证明，这本书内容很丰富，值得反复阅读，其中的很多内容我都很欣赏。比如说这几节：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;知道我今天为什么来上班吗？好公司与烂公司的区别&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;创业公司为什么要进行人员培训&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;其中这节讲到了 &lt;code class=&quot;highlighter-rouge&quot;&gt;好的产品经理，差的产品经理&lt;/code&gt; 的故事，非常有鉴赏学习价值。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;该不该招资深人士&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;打造企业文化&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总结：&lt;em&gt;从0到1&lt;/em&gt; 和 &lt;em&gt;创业维艰&lt;/em&gt; 这两本书最近很火，可是最近看下来，我对 &lt;em&gt;创业维艰&lt;/em&gt; 这本书更喜欢，这是一本我觉得好的，并且会花钱买纸板的，并且会推荐给朋友看的书，特别是对于想要创业，正在创业中的同事，我强烈推荐。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;successful-negotiation-essential-strategies-and-skillshttpswwwcourseraorglearnnegotiation-skills&quot;&gt;1.10 &lt;a href=&quot;https://www.coursera.org/learn/negotiation-skills/&quot;&gt;Successful Negotiation: Essential Strategies and Skills&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是 coursera 上的一门公开课，讲商业谈判的。老师说话很清晰，课件也做得非常好，这门课我有单独做笔记的，稍后会放出来。就课程内容而言，我很喜欢，梳理了很多商业谈判的思考和执行流程，对销售人员我觉得用处很大。&lt;/p&gt;

&lt;p&gt;总结：这位老师讲得非常详细，例子也简单明了，课件清晰易懂，内容很丰富，值得学习。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httppanbaiducoms1borig5t-1&quot;&gt;1.11.1 &lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;研报系列: 大数据深度学习系列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;smartalphahttppanbaiducoms1borig5t&quot;&gt;1.11.2 &lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;研报系列: 兴业金工-SmartAlpha系列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httppanbaiducoms1borig5t-2&quot;&gt;1.11.3 &lt;a href=&quot;http://pan.baidu.com/s/1boRIG5T&quot;&gt;研报系列：聪明贝塔创造超额收益的秘密&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;phbs---httpsmpweixinqqcomsbizmzaxmtgxotk1mgmid2652253014idx1snb46105f151dada9072b7e532f1039ce6scene1srcid042918y41xwxir3vkcze4vaikeyb28b03434249256bca154929931849b7030dd828c272e65879cb4066d506bd78a0cd49cee81f5897c05b4ee8029eebceascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketzro6lfuwcyd7lyl1iizja8mspeixaymakvhlukmp28ql9zuuwg5v463an4rqy0hs&quot;&gt;1.11.4 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAxMTgxOTk1Mg==&amp;amp;mid=2652253014&amp;amp;idx=1&amp;amp;sn=b46105f151dada9072b7e532f1039ce6&amp;amp;scene=1&amp;amp;srcid=042918Y41xWXir3VkCzE4Vai&amp;amp;key=b28b03434249256bca154929931849b7030dd828c272e65879cb4066d506bd78a0cd49cee81f5897c05b4ee8029eebce&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=ZRo6lfuwcyd7LYl1iiZja8mspEIxaYmAkVHLUKMP28QL9ZUUWG5v463an4rQY0HS&quot;&gt;研报系列: PHBS 之 【内培分享】股票之量化择时 &lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 博文推荐&lt;/h2&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mtqznzu2namid2651640686idx1snc2053e953b94f2b6133230c2d0b48d83scene0keyb28b03434249256b1d6facc8de2ef11e0e4dcbdf601d1b76f0eb49a592cba264c4613048cc1946d7e2048b13dd15aa02ascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.1 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=2651640686&amp;amp;idx=1&amp;amp;sn=c2053e953b94f2b6133230c2d0b48d83&amp;amp;scene=0&amp;amp;key=b28b03434249256b1d6facc8de2ef11e0e4dcbdf601d1b76f0eb49a592cba264c4613048cc1946d7e2048b13dd15aa02&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;大数据背后的神秘公式（上）：贝叶斯公式&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mtqznzu2namid2651640692idx1sneffef2d07f3afc0e6506d45633e3f771scene0keyb28b03434249256b8a2e9811f53c2873930c9c4ab8fc855d766a6bdac7001085057ba88e71803c6bd7f0a00614c44fc8ascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.2 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=2651640692&amp;amp;idx=1&amp;amp;sn=effef2d07f3afc0e6506d45633e3f771&amp;amp;scene=0&amp;amp;key=b28b03434249256b8a2e9811f53c2873930c9c4ab8fc855d766a6bdac7001085057ba88e71803c6bd7f0a00614c44fc8&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;大数据背后的神秘公式（下）：贝叶斯革命&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;apache-kafka-httpwwwibmcomdeveloperworkscnopensourceos-cn-kafkaindexhtml&quot;&gt;2.3 &lt;a href=&quot;http://www.ibm.com/developerworks/cn/opensource/os-cn-kafka/index.html&quot;&gt;Apache kafka 工作原理介绍&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mtqznzu2namid403145071idx1sn7ab3a8fd92b622d3cd7362db5b20b82ascene0keyb28b03434249256bf46f5ae8286a91d594b55d0f3f709de24e82865fa245df906c24fdbd0dc7bb12df7f9e8ed45c7a37ascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.4 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=403145071&amp;amp;idx=1&amp;amp;sn=7ab3a8fd92b622d3cd7362db5b20b82a&amp;amp;scene=0&amp;amp;key=b28b03434249256bf46f5ae8286a91d594b55d0f3f709de24e82865fa245df906c24fdbd0dc7bb12df7f9e8ed45c7a37&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;优秀的数据产品经理如何炼成&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;这些都是讲方法论的，个人觉得想要在自己所在的行业做到优秀，最核心，最关键的因素是自己打心底爱这个职业。人生两大境界：爱我所做，做我所爱。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mdmymzg2mamid407893431idx1snbceacc10da607cb6b0e7c5d14c963b90scene0keyb28b03434249256b37259de5b86de1aed3f2f01e22bb962ca1590d9c6f9966bfcbf006f7be14d7d93377444fe2388ecfascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.5 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDMyMzg2MA==&amp;amp;mid=407893431&amp;amp;idx=1&amp;amp;sn=bceacc10da607cb6b0e7c5d14c963b90&amp;amp;scene=0&amp;amp;key=b28b03434249256b37259de5b86de1aed3f2f01e22bb962ca1590d9c6f9966bfcbf006f7be14d7d93377444fe2388ecf&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;情商高就是心里装着别人&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mzu1ntqznqmid402506711idx1sn9b6cb08013e6eeeaa8f9e2685b927239scene0keyb28b03434249256b0b41bf07161162782850f60db9a4a83fea5016eda2be43295e33240989a80ed10c56deb90cdaabcaascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.6 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MzU1NTQzNQ==&amp;amp;mid=402506711&amp;amp;idx=1&amp;amp;sn=9b6cb08013e6eeeaa8f9e2685b927239&amp;amp;scene=0&amp;amp;key=b28b03434249256b0b41bf07161162782850f60db9a4a83fea5016eda2be43295e33240989a80ed10c56deb90cdaabca&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;凯利公式——仓位控制的利器&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5nzewntmwmamid403311481idx1sn7b597caceb57c69b3c53c052e0050cf2scene0keyb28b03434249256be55dc6bc20a8bc9b34fe45739f7a6d6ec9fc84dde0eafabb7fa00e636f05592c74d23c3bac40654cascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.7 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NzEwNTMwMA==&amp;amp;mid=403311481&amp;amp;idx=1&amp;amp;sn=7b597caceb57c69b3c53c052e0050cf2&amp;amp;scene=0&amp;amp;key=b28b03434249256be55dc6bc20a8bc9b34fe45739f7a6d6ec9fc84dde0eafabb7fa00e636f05592c74d23c3bac40654c&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;「滚床单」有哪些优雅的叫法？&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;轻松一下，哈哈。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mde0mjc4mamid402796490idx1sn5f9fd2dbd9d0030c954084f2df75d410scene0keyb28b03434249256bcc21f98e1dce38db43a18cba063d4f11b77c9091c999e698be4dfddc847ac0ec70d1785d3f3d0473ascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.8 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=402796490&amp;amp;idx=1&amp;amp;sn=5f9fd2dbd9d0030c954084f2df75d410&amp;amp;scene=0&amp;amp;key=b28b03434249256bcc21f98e1dce38db43a18cba063d4f11b77c9091c999e698be4dfddc847ac0ec70d1785d3f3d0473&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;从算法到案例：推荐系统必读的10篇精选技术文章&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;httpsmpweixinqqcomsbizmjm5mde0mjc4mamid402656056idx1sn2ebfde6f4df33ec690836f22c7f14d07scene0keyb28b03434249256b1d5444866538d49c0aa9cc9979fe2fecc4a249659942d85afdb654ce26577ded111a887c020c517fascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketmboekjt4scekrgkop52x3dw7dtf706nn06oet3552iiocf4nfr7p2fec0dm3jc7z3&quot;&gt;2.9 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=402656056&amp;amp;idx=1&amp;amp;sn=2ebfde6f4df33ec690836f22c7f14d07&amp;amp;scene=0&amp;amp;key=b28b03434249256b1d5444866538d49c0aa9cc9979fe2fecc4a249659942d85afdb654ce26577ded111a887c020c517f&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;推荐系统和搜索引擎的关系&lt;/a&gt;&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;曾经被问到过的一个问题，其实看了本文大多数人应该都有感触 ：”对啊，就这几个简单的区别嘛，我知道啊”。但是，”知道” 和 “能清晰简捷的表述出来” 之间的差别还是很大的, that tells the difference。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;httpwwwinfoqcomcnarticles20-outstanding-enterprise-technology-blog&quot;&gt;2.10 &lt;a href=&quot;http://www.infoq.com/cn/articles/20-outstanding-enterprise-technology-blog&quot;&gt;最值得关注的20个优秀企业技术博客&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;in-startups-and-life-you-need-plan-a-b-and-zhttptechcrunchcom20120214in-startups-and-life-you-need-plan-a-b-and-z&quot;&gt;2.11 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;In Startups And Life, You Need Plan A, B, And Z&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;githubhttpsmpweixinqqcomsbizmjm5mzm3njm4mamid2654675314idx4sn841dacff037413cd290c691dca609a81scene0keyb28b03434249256bf0f6bffac4d224a7b5968a0c614784efcb6ab64dd13fa148235f7863184e6e75702c3a61550b7a3cascene0uinmtazntc2nzm4mg3d3ddevicetypeimacmacbookair62c2osxosx10105build14f1605version11020201passticketodhk3wvwf6tilgqsv51gbzwyzkwkfp2q0schpmkwqckg72bfu1kkvjjq0mwpw8f52&quot;&gt;2.12 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MzM3NjM4MA==&amp;amp;mid=2654675314&amp;amp;idx=4&amp;amp;sn=841dacff037413cd290c691dca609a81&amp;amp;scene=0&amp;amp;key=b28b03434249256bf0f6bffac4d224a7b5968a0c614784efcb6ab64dd13fa148235f7863184e6e75702c3a61550b7a3c&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=odHK3wvWF6tiLGqSv51GbzWYZKWKFp2q0sChpmkwqCKg7%2Bfu1KKvJjq0MwPW8f52&quot;&gt;安全专业人士最爱的19个GitHub开源项目&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;githttpblogcsdnnetqwe6112071articledetails51118761&quot;&gt;2.13 &lt;a href=&quot;http://blog.csdn.net/qwe6112071/article/details/51118761&quot;&gt;git分支原理命令图文解析&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;sysdiglinuxhttpslinuxcnarticle-4341-1html&quot;&gt;2.14 &lt;a href=&quot;https://linux.cn/article-4341-1.html&quot;&gt;系统之锹sysdig：Linux服务器监控和排障利器&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;spark-architecturehttps0x0fffcomspark-architecture&quot;&gt;2.15 &lt;a href=&quot;https://0x0fff.com/spark-architecture/&quot;&gt;Spark Architecture&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;hadoophttpblogfensmehadoop-family-roadmap&quot;&gt;2.16 &lt;a href=&quot;http://blog.fens.me/hadoop-family-roadmap/&quot;&gt;Hadoop家族学习路线图&lt;/a&gt;&lt;/h3&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 读书总结系列&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-mar-2016&quot;&gt;『 读书笔记 』3月读书总结和推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-apr-2016&quot;&gt;『 读书笔记 』4月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境</title>
     <link href="/ipython-notebook-spark"/>
     <updated>2016-04-10T00:00:00+08:00</updated>
     <id>/ipython-notebook-spark</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 致谢&lt;/h2&gt;

&lt;p&gt;首先我忠心地感谢 IPython，Spark 的开源作者，真心谢谢你们开发这么方便，好用，功能强大的项目，而且还无私地奉献给大众使用。刚刚很轻松地搭建了一个机遇 IPython Notebook 的 Spark 客户端，真的感受到 The power of technology, the power of open source.&lt;br /&gt;
下面是这两个项目的 github 地址：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ipython/ipython&quot;&gt;Ipython&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/apache/spark&quot;&gt;Spark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;同时，这篇文章在刚开始的部分，参考了很多 &lt;a href=&quot;http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/&quot;&gt;这篇博客&lt;/a&gt;的内容，感谢这么多人能无私分享如此高质量的内容。 &lt;br /&gt;
但是，这篇文章不是简单记录怎么做，我尽量做到量少质高，所以有些地方会说得比较详细，其中也会提到在解决遇到的问题上的一些方法和思路。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 原理&lt;/h2&gt;

&lt;p&gt;Ipython 支持自定义的配置文件，而且配置文件可以极其灵活的定义，我们可以借此在启动 IPython 的时候去做一些自定义的事，比如说加载一些模块，做一些初始化的工作。这里我们就是利用 Ipython 的这个灵活的特性，在启动 Ipython 的时候，自动加载 spark 的 pyspark 包，甚至是初始化一个 SparkContext。&lt;/p&gt;

&lt;p&gt;具体我们来看如何创建一个配置文件，并且指定一个配置文件启动 ipython。&lt;/p&gt;

&lt;h2 id=&quot;ipython&quot;&gt;3. 配置Ipython&lt;/h2&gt;

&lt;h3 id=&quot;ipython-profile&quot;&gt;3.1 ipython 配置名profile介绍&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;profile 命令说明&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;profile 是 ipython 的一个子命令，其中 profile 又有两个子命令，分别是 create和list，顾名思义，create就是创建一个配置文件，list就是列出当前配置文件。如下：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;root@ubuntu2[13:54:01]:~/Desktop#ipython profile
No subcommand specified. Must specify one of: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;create&#39;&lt;/span&gt;, &lt;span class=&quot;s1&quot;&gt;&#39;list&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;

Manage IPython profiles

Profile directories contain configuration, log and security related files and
are named using the convention &lt;span class=&quot;s1&quot;&gt;&#39;profile_&amp;lt;name&amp;gt;&#39;&lt;/span&gt;. By default they are located &lt;span class=&quot;k&quot;&gt;in
&lt;/span&gt;your ipython directory.  You can create profiles with &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;ipython profile create
&amp;lt;name&amp;gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;, or see the profiles you already have with &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;ipython profile list&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;

To get started configuring IPython, simply &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;:

&lt;span class=&quot;gp&quot;&gt;$&amp;gt; &lt;/span&gt;ipython profile create

and IPython will create the default profile &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &amp;lt;ipython_dir&amp;gt;/profile_default,
where you can edit ipython_config.py to start configuring IPython.

Subcommands
-----------

Subcommands are launched as &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;ipython cmd &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;args]&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;. For information on using
subcommand &lt;span class=&quot;s1&quot;&gt;&#39;cmd&#39;&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;: &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;ipython cmd -h&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;.

create
    Create an IPython profile by name
list
    List available IPython profiles&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;profile子命令 list 说明&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本想 list 命令应该很简单的，和 linux 下的 ls 差不多嘛，但我自己看了下，其中还是有些细节值得推敲的。其中这项 &lt;em&gt;Available profiles in /root/.config/ipython:&lt;/em&gt; 是说目前有两个配置文件在那个目录下面，pyspark是我自己创建的了。在参考的&lt;a href=&quot;http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/&quot;&gt;这篇文章&lt;/a&gt;中，作者说创建的配置文件会放到 &lt;em&gt;~/.ipython/profile_pyspark/&lt;/em&gt; 下，其实这并不是一定的，具体放在哪个目录下面，可以根据 profile list 的命令来查看。如此看来，我们在这台机器上创建的配置文件应该是放在目录 &lt;em&gt;/root/.config/ipython&lt;/em&gt; 下面的。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;root@ubuntu2[14:09:12]:~/Desktop#ipython profile list

Available profiles &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;IPython:
    pysh
    math
    sympy
    cluster

    The first request &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;a bundled profile will copy it
    into your IPython directory &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/root/.config/ipython&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,
    where you can customize it.

Available profiles &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /root/.config/ipython:
    default
    pyspark

To use any of the above profiles, start IPython with:
    ipython --profile&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;name&amp;gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;profile子命令 create 说明&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;简单介绍下create子命令的用法。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;root@ubuntu2[09:25:57]:~/Desktop#ipython profile &lt;span class=&quot;nb&quot;&gt;help &lt;/span&gt;create
Create an IPython profile by name

Create an ipython profile directory by its name or profile directory path.
Profile directories contain configuration, log and security related files and
are named using the convention &lt;span class=&quot;s1&quot;&gt;&#39;profile_&amp;lt;name&amp;gt;&#39;&lt;/span&gt;. By default they are located &lt;span class=&quot;k&quot;&gt;in
&lt;/span&gt;your ipython directory. Once created, you will can edit the configuration files
&lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the profile directory to configure IPython. Most users will create a profile
directory by name, &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;ipython profile create myprofile&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;, which will put the
directory &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&amp;lt;ipython_dir&amp;gt;/profile_myprofile&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;ipython-1&quot;&gt;3.2 创建新的Ipython配置文件&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;创建配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为我之前已经配置过一个pyspark的配置文件了，这里我们创建一个测试用的配置文件，pytest。运行一下命令后，会在 &lt;em&gt;/root/.config/ipython&lt;/em&gt; 下生成一个 pytest 的目录。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;root@ubuntu2[14:54:14]:~/Desktop#ipython profile create pytest
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ProfileCreate] Generating default config file: u&lt;span class=&quot;s1&quot;&gt;&#39;/root/.config/ipython/profile_pytest/ipython_config.py&#39;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ProfileCreate] Generating default config file: u&lt;span class=&quot;s1&quot;&gt;&#39;/root/.config/ipython/profile_pytest/ipython_notebook_config.py&#39;&lt;/span&gt;

root@ubuntu2[15:00:57]:~/Desktop#ls ~/.config/ipython/profile_pytest/
ipython_config.py  ipython_notebook_config.py  log  pid  security  startup&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;section-3&quot;&gt;3.3 编辑配置文件&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;编辑 &lt;em&gt;ipython_notebook_config.py&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;需要更改的只有下面三项：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;c.NotebookApp.ip&lt;/em&gt;: 启动服务的地址，设置成 ‘*’ 可以从同一网段的其他机器访问到；&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;c.NotebookApp.open_browser&lt;/em&gt;: 设置成 ‘False’，表示启动 ipython notebook 的时候不会自动打开浏览器；&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;c.NotebookApp.password&lt;/em&gt;: 设置 ipython notebook 的登陆密码，怎么设置看下面；&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NotebookApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;*&#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NotebookApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_browser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;    
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NotebookApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;sha1:c6b748a8e1e2:4688f91ccfb9a8e0afd041ec77cdda99d0e1fb8f&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;设置访问密码 &lt;br /&gt;
如果你的 notebook server 是需要访问控制的，简单的话可以设置一个访问密码。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;生成密码&lt;/li&gt;
      &lt;li&gt;编辑配置文件，设置密码&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython.lib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;passwd&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;passwd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Enter&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Verify&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;sha1:e819609871c8:1039dbc5a1392fc230d371d1ce19511490978685&#39;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### set password &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NotebookApp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;sha1:c6b748a8e1e2:4688f91ccfb9a8e0afd041ec77cdda99d0e1fb8f&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;设置启动文件&lt;br /&gt;
这一步算是比较重要的了，也是我在配置这个notebook server中遇到的比较难解的问题。这里我们首先需要创建一个启动文件，并在启动文件里设置一些spark的启动参数。如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@ubuntu2[09:52:14]:~/Desktop#touch ~/.config/ipython/profile_pytest/startup/00-pytest-setup.py
root@ubuntu2[10:08:44]:~/Desktop#vi ~/.config/ipython/profile_pytest/startup/00-pytest-setup.py   

import os
import sys

spark_home = os.environ.get(&#39;SPARK_HOME&#39;, None)
if not spark_home:
    raise ValueError(&#39;SPARK_HOME environment variable is not set&#39;)
sys.path.insert(0, os.path.join(spark_home, &#39;python&#39;))
sys.path.insert(0, os.path.join(spark_home, &#39;python/lib/py4j-0.8.2.1-src.zip&#39;))
# execfile(os.path.join(spark_home, &#39;python/pyspark/shell.py&#39;))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面的启动配置文件也还简单，即拿到 &lt;em&gt;spark_home&lt;/em&gt; 路径，并在系统环境变量 path 里加上两个路径，然后再执行一个 &lt;em&gt;shell.py&lt;/em&gt; 文件。不过，在保存之前还是先确认下配置文件写对了，比如说你的 SPARK_HOME 配置对了，并且下面有 python 这个文件夹，并且 &lt;em&gt;python/lib 下有 py4j-0.8.1&lt;/em&gt; 这个文件。我在检查的时候就发现我的包版本是 py4j-0.8.2.1 的，所以还是要改得和自己的包一致才行。 &lt;br /&gt;
这里得到一个经验，在这种手把手，step by step的教程中，一定要注意版本控制，毕竟各人的机器，操作系统，软件版本等都不可能完全一致，也许在别人机器上能成功，在自己的机器上不成功也是很正常的事情，毕竟细节决定成败啊！所以在我这里，这句我是这样写的： &lt;em&gt;sys.path.insert(0, os.path.join(spark_home, ‘python/lib/py4j-0.8.2.1-src.zip’))&lt;/em&gt;  &lt;br /&gt;
注意，上面的最后一行 &lt;em&gt;execfile(os.path.join(spark_home, ‘python/pyspark/shell.py’))&lt;/em&gt; 被注释掉了，表示在新建或打开一个 notebook 时并不去执行 &lt;em&gt;shell.py&lt;/em&gt; 这个文件，这个文件是创建 SparkContext 的，即如果执行改行语句，那在启动 notebook 时就会初始化一个 sc，但这个 sc 的配置都是写死了的，在 spark web UI 监控里的 appName 也是一样的，很不方便。而且考虑到并不是打开一个 notebook 就要用到 spark 的资源，所以最好是要用户自己定义 sc 了。&lt;/p&gt;

&lt;p&gt;python/pyspark/shell.py 的核心代码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sc = SparkContext(appName=&quot;PySparkShell&quot;, pyFiles=add_files)
atexit.register(lambda: sc.stop())
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;okhere-we-go&quot;&gt;4. Ok，here we go&lt;/h2&gt;
&lt;p&gt;到这里差不多大功告成了，可以启动notebook server了。不过在启动之前，需要配置两个环境变量参数，同样，这两个环境变量参数在也是根据个人配置而定的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# for the CDH-installed Spark
export SPARK_HOME=&#39;/usr/local/spark-1.2.0-bin-cdh4/&#39;

# this is where you specify all the options you would normally add after bin/pyspark
export PYSPARK_SUBMIT_ARGS=&#39;--master spark://10.21.208.21:7077 --deploy-mode client&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ok，万事具备，只欠东风了。让我们来尝尝鲜吧：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@ubuntu2[10:40:50]:~/Desktop#ipython notebook --profile=pyspark
2015-02-01 10:40:54.850 [NotebookApp] Using existing profile dir: u&#39;/root/.config/ipython/profile_pyspark&#39;
2015-02-01 10:40:54.858 [NotebookApp] Using MathJax from CDN: http://cdn.mathjax.org/mathjax/latest/MathJax.js
2015-02-01 10:40:54.868 [NotebookApp] CRITICAL | WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
2015-02-01 10:40:54.869 [NotebookApp] Serving notebooks from local directory: /root/Desktop
2015-02-01 10:40:54.869 [NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8880/
2015-02-01 10:40:54.869 [NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在浏览器输入driver:8880即可访问notebook server了，首先会提示输入密码，密码正确后就可以使用了。
&lt;img src=&quot;http://litaotao.github.io/images/notebook-spark-1.jpg&quot; alt=&quot;notebook-spark-1&quot; /&gt;
&lt;img src=&quot;http://litaotao.github.io/images/notebook-spark-2.jpg&quot; alt=&quot;notebook-spark-2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;5. 总结&lt;/h2&gt;
&lt;p&gt;下面是简单的步骤总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;建立环境变量配置文件：*ipython_notebook_spark.bashrc *&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export SPARK_HOME=&quot;/usr/local/spark-1.2.0-bin-cdh4/&quot;
export PYSPARK_SUBMIT_ARGS=&quot;--master spark://10.21.208.21:7077 --deploy-mode client&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;配置Ipython notebook server
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;ipython profile create pyspark&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;编辑 &lt;em&gt;ipython_notebook_config.py&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;[可选]配置ipython notebook登录密码&lt;/li&gt;
      &lt;li&gt;设置启动文件&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;设置启动脚本&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;next&quot;&gt;4. next&lt;/h2&gt;

&lt;p&gt;这个例子还算 ok 吧，可是我每天都应用的投资策略的一部分啊，已经下血本了，各位还不打赏打赏吗？一转眼 spark 已经快要有十篇 blog 了，期间也写了一些 spark 的应用程序，读了一些高质量的书和博文，在 youtube 上也看了一些高质量的技术分享。也总结了一些写 spark 应用程序的时候的细节问题，下一篇就列一下这些细节问题，希望能优化，加速各位的 spark 应用程序。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测</title>
     <link href="/spark-in-finance-and-investing"/>
     <updated>2016-04-01T00:00:00+08:00</updated>
     <id>/spark-in-finance-and-investing</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 同花顺收费版之走势预测&lt;/h2&gt;

&lt;p&gt;2014年后半年开始，国内 A 股市场可谓是热火朝天啊，路上的人谈的都是股票。小弟虽然就职金融互联网公司，但之前从来没有买过股票，但每天听着别人又赚了几套房几辆车，那叫一个心痒痒啊，那感觉，就跟一个出浴美女和你共处一室，但你却要死忍住不去掀开浴巾一样。终于，小弟还是”犯了全天下男人都会犯的错误”，还是在 2015.03.19 那天入市了，还记得自己的第一次是献给了一支叫 &lt;code class=&quot;highlighter-rouge&quot;&gt;天建集团&lt;/code&gt; 的股票，好像当天还赚了一两百块吧，当时心情那叫一个激动，下班了第一时间就打电话给娘亲了。&lt;/p&gt;

&lt;p&gt;哦，似乎有点扯得远了。言归正传，当时自己为了投资更方便，就花了将近 300 大洋买了同花顺的 level 2 版，里面有个功能，叫做 &lt;code class=&quot;highlighter-rouge&quot;&gt;形态预测&lt;/code&gt;。具体就是，根据所有股票的历史行情，看看当前股票的未来一段时间的走势分布。下面是一个截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-in-finance-1.jpg&quot; alt=&quot;spark-in-finance-1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;截图说明：颜色越深，概率越大，包括一组预测的 k 线走势。就像上面说的，上面的那支股票的预测结果是：未来3周收益大于 4.0% 的概率有 60%。amazing…&lt;/p&gt;

&lt;p&gt;先不说这个预测准确度有多高，但首先这个思路不错，至少可以作为一个信号吧［当然一个稳健的投资策略肯定不能仅仅依赖于一个信号］&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 形态选股&lt;/h2&gt;

&lt;p&gt;同花顺这个功能，其实也挺实用的，因为本身在股票市场技术指标这个分类下面，就有形态选股这样一种指标。比如说，经常听财经频道主持人说的 &lt;a href=&quot;http://baike.baidu.com/item/%E4%B8%89%E9%98%B3%E5%BC%80%E6%B3%B0/18751451&quot;&gt;三阳开泰&lt;/a&gt;，&lt;a href=&quot;http://baike.baidu.com/view/1302521.htm&quot;&gt;圆弧底&lt;/a&gt; 什么的。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 指数日内相似度&lt;/h2&gt;

&lt;p&gt;今天，我们就来尝试一下，通过指数日内走势来进行宏观择时: 我们在早盘 11:00 时，使用当天上证指数的分时图，预测一下当天走势情况。&lt;/p&gt;

&lt;p&gt;原理如下：使用上证指数历史分时数据，计算历史上每天 09:30 到 11:00 的分时段走势与今天早盘 09:30 到 11:00 走势的相似度。我们认为，相似度越高，则今日 11:00 到 15:00 走势和 15:00 的收盘涨跌，与历史当日的走势和收盘涨跌有较大的相似度。&lt;/p&gt;

&lt;p&gt;结果预览，如下图所示哦：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-in-finance-2.jpg&quot; alt=&quot;spark-in-finance-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;spark-&quot;&gt;4. spark 实现指数日内相似度&lt;/h2&gt;

&lt;p&gt;同样，我们也用第三篇 &lt;a href=&quot;../spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt; 讲到的三个步骤来实现这个简单的，但有实践意义的 spark 应用程序。&lt;/p&gt;

&lt;p&gt;备注：为了方便理解，我把这个例子精简过了，只用上证指数 6 年的分钟线数据，对应的相似度算法也是采用最简单的算法。但是不影响对整个应用框架的理解和扩展。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;4.1 加载数据集&lt;/h3&gt;

&lt;p&gt;本文用到的数据集已经上传到百度云了，上传文件是一个压缩文件，解压缩后把整个文件夹上传到 hadoop 上就行了，文件夹里有 1505 个文件，文件名表示上证指数某日的分钟线行情，文件内容即为历史当日分钟线行情：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-in-finance-3.jpg&quot; alt=&quot;spark-in-finance-3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下载链接：&lt;a href=&quot;http://pan.baidu.com/s/1jIvW4mU&quot;&gt;minute_bar.zip on baidu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下面，我们先创建 SparkContext，然后加载存放在 hdfs 上的数据。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### 创建 sc&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### 加载 hdfs 上的数据&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;hdfs://10.21.208.21:8020/user/mercury/minute_bar&#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rdd_mkt_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wholeTextFiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
                 &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;index_minute_bar&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
                 &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;section-5&quot;&gt;4.2 处理数据&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;指定要预测的分钟线&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### UDF 函数，从 rdd_mkt_data 获取某日历史分钟线行情数据&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;minute_bar_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd_mkt_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;barTime&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### 指定想要预测的线的 id，这里我们预测上证指数 2016.03.17 的分钟线&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;000001.ZICN-20160317&#39;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 指定用于计算相似度的分钟线长度，这里我们用 90 个分钟 bar，&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;### 即开盘 09:30 到 11:00 的分钟线&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;minute_bar_length_share&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target_line_mkt_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_bar_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target_line_share&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_line_mkt_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;计算相似度&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### 相似度计算函数&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cal_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;计算相似度
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;### 使用 sklearn，pandas 来简化计算流程&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### 通过广播变量获取预测的目标线和准备用来预测的分钟线长度&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;minute_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_bar_length_share&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_line_share&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### 参数 line 的格式是： (line_id, line_data)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### 获取 pandas dataframe 格式的某日分钟线行情&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ticker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tradeDate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;-&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;barTime&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### 每天有 240 条分钟线的 bar，我们用 前 minute_length 来计算相似度&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;first&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;second&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;diff&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;first&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;second&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;diff_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;diff&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;### 返回格式：(分钟线id，该分钟线和目标线前 minute_length 个长度的相似度)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                


&lt;span class=&quot;c&quot;&gt;### spark 相似度计算代码&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rdd_similarity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd_mkt_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
                             &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;rdd_similarity&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
                             &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;section-6&quot;&gt;4.3 结果展示&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;获取相似度高的分钟线&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### UDF，从 rdd_mkt_data 里获取指定的多日分钟线数据&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_similary_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;### 获取原始相似的分钟线数据&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rdd_lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd_mkt_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;### 把原始分钟线数据转成 pandas dataframe 格式&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd_lines&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;barTime&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### 获取相似度最高的30日分钟线&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rdd_similarity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;takeOrdered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_similary_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;根据相似分钟线绘制预测图&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;draw_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similar_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;minute&#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;minute&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;barTime&lt;/span&gt;  
        &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;fitting&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;target_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_line_mkt_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### plot &lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;minute&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                  &lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;u&#39;Minute Bar Prediction&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;target_line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;.b&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;fitting&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;-y&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;linestyles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;dashed&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_bgcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;white&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;gray&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;y&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;### plot area&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;fitting&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;predict_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;predict_line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill_between&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;241&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                        &lt;span class=&quot;n&quot;&gt;predict_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minute_bar_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarity_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-in-finance-2.jpg&quot; alt=&quot;spark-in-finance-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;next&quot;&gt;5. Next&lt;/h2&gt;

&lt;p&gt;这个例子还算 ok 吧，可是我每天都应用的投资策略的一部分啊，已经下血本了，各位还不打赏打赏吗？一转眼 spark 已经快要有十篇 blog 了，本来原计划第九篇是总结一些 spark 性能优化的 tips 的。可是前几天一个朋友突然问我是怎么开发 spark 应用程序的。我才恍然大悟，一下子写了这么多篇，都没有把搭建开发环境的经验写出来的呢。&lt;/p&gt;

&lt;p&gt;下一篇我就总结一下自己怎么搭建的一个 ipython + spark 的开发环境；不管各位有没有用过 ipython [notebook]，我都强烈推荐使用，使用它能打打提高你的开发效率和开发体验，你一定会爱上他的，相信我。&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;6. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-8&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes&quot;&gt;Spark SQL, DataFrames and Datasets Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html&quot;&gt;Introducing DataFrames in Spark for Large Scale Data Science&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.databricks.com/questions/7257/from-webinar-spark-dataframes-what-is-the-differen-1.html&quot;&gt;From Webinar Apache Spark 1.5: What is the difference between a DataFrame and a RDD?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/apache-spark-sql&quot;&gt;用Apache Spark进行大数据处理——第二部分：Spark SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/02/an-introduction-to-json-support-in-spark-sql.html&quot;&gt;An introduction to JSON support in Spark SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.csdn.net/article/2015-02-18/2823997&quot;&gt;Spark新年福音：一个用于大规模数据科学的API——DataFrame&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/02/an-introduction-to-json-support-in-spark-sql.html&quot;&gt;An introduction to JSON support in Spark SQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-9&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Spark 』7. 使用 Spark DataFrame 进行大数据分析</title>
     <link href="/spark-dataframe-introduction"/>
     <updated>2016-03-30T00:00:00+08:00</updated>
     <id>/spark-dataframe-introduction</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;spark-dataframe&quot;&gt;1. 什么是 spark dataframe&lt;/h2&gt;

&lt;p&gt;先来看看官方原汁原味的文档是怎么介绍的：&lt;/p&gt;

&lt;p&gt;A DataFrame is &lt;code class=&quot;highlighter-rouge&quot;&gt;a distributed collection of data&lt;/code&gt; organized into named columns. It is conceptually equivalent to a &lt;code class=&quot;highlighter-rouge&quot;&gt;table in a relational database&lt;/code&gt; or a data frame in R/Python, but with &lt;code class=&quot;highlighter-rouge&quot;&gt;richer optimizations&lt;/code&gt; under the hood. DataFrames can be constructed from a wide array of sources such as: &lt;code class=&quot;highlighter-rouge&quot;&gt;structured data files, tables in Hive, external databases, or existing RDDs&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;我们可以看到 spark dataframe 的几个关键点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分布式的数据集&lt;/li&gt;
  &lt;li&gt;类似关系型数据库中的table，或者 excel 里的一张 sheet，或者 python/R 里的 dataframe&lt;/li&gt;
  &lt;li&gt;拥有丰富的操作函数，类似于 rdd 中的算子&lt;/li&gt;
  &lt;li&gt;一个 dataframe 可以被注册成一张数据表，然后用 sql 语言在上面操作&lt;/li&gt;
  &lt;li&gt;丰富的创建方式
    &lt;ul&gt;
      &lt;li&gt;已有的RDD&lt;/li&gt;
      &lt;li&gt;结构化数据文件&lt;/li&gt;
      &lt;li&gt;JSON数据集&lt;/li&gt;
      &lt;li&gt;Hive表&lt;/li&gt;
      &lt;li&gt;外部数据库&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-dataframe-1&quot;&gt;2. 为什么要用 spark dataframe&lt;/h2&gt;

&lt;p&gt;为什么要用 dataframe，从细节实现上来说，这个问题比较复杂，不过，基本上下面这张图就能说明所有问题了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-flow.png&quot; alt=&quot;spark-dataframe-flow.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是，本文是从基础角度来说 spark dataframe，先不纠结这些细节问题，先了解一些基础的原理和优势，关于上面那张图里面的内容，看后期安排，也许在之后第 15 篇左右会专门讲。&lt;/p&gt;

&lt;p&gt;DataFrame API 是在 R 和 Python data frame 的设计灵感之上设计的，具有以下功能特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从KB到PB级的数据量支持；&lt;/li&gt;
  &lt;li&gt;多种数据格式和多种存储系统支持；&lt;/li&gt;
  &lt;li&gt;通过Spark SQL 的 Catalyst优化器进行先进的优化，生成代码；&lt;/li&gt;
  &lt;li&gt;通过Spark无缝集成所有大数据工具与基础设施；&lt;/li&gt;
  &lt;li&gt;为Python、Java、Scala和R语言（SparkR）API；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;简单来说，dataframe 能够更方便的操作数据集，而且因为其底层是通过 spark sql 的 Catalyst优化器生成优化后的执行代码，所以其执行速度会更快。总结下来就是，使用 spark dataframe 来构建 spark app，能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;write less : 写更少的代码&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;do more : 做更多的事情&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;faster : 以更快的速度&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dataframe&quot;&gt;3. 创建 dataframe&lt;/h2&gt;

&lt;p&gt;因为 spark sql，dataframe，datasets 都是共用 spark sql 这个库的，三者共享同样的代码优化，生成以及执行流程，所以 sql，dataframe，datasets 的入口都是 sqlContext。可用于创建 spark dataframe 的数据源有很多，我们就讲最简单的从结构化文件创建 dataframe。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-3.jpg&quot; alt=&quot;spark-dataframe-3.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step 1 : 创建 sqlContext&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是我自己创建 spark sc 都模版：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setAppName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;03-DataFrame-01&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setMaster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SPARK_MASTER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;spark.executor.memory&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;2g&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;spark.logConf&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc_conf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SQLContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;step 2 : 创建 dataframe，从 json 文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据文件说明：中国 A 股上市公司基本信息，可以在这里取到：&lt;a href=&quot;http://pan.baidu.com/s/1pLxN851&quot;&gt;stock_5.json&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-1.jpg&quot; alt=&quot;spark-dataframe-1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：这里的 json 文件并不是标准的 json 文件，spark 目前也不支持读取标准的 json 文件。你需要预先把标准的 json 文件处理成 spark 支持的格式: 每一行是一个 json 对象。&lt;/p&gt;

&lt;p&gt;比如说，官网的 &lt;code class=&quot;highlighter-rouge&quot;&gt;people.json&lt;/code&gt; 这个例子，它要求的格式是：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Yin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Columbus&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ohio&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Michael&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;California&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;但对这个文件来看，标准的 json 格式只有下面两种：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Yin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Michael&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Columbus&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ohio&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;California&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;###&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;或者&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Yin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Columbus&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ohio&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Michael&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;address&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;California&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;所以在用 spark sql 来读取一个 json 文件的时候，务必要提前处理好 json 的文件格式，这里我们已经提前处理好了，文件如下所示：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ticker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;000001&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tradeDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-03-30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;exchangeCD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;XSHE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;secShortName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\u5e73\u5b89\u94f6\u884c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;preClosePrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;openPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dealAmount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;19661&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;turnoverValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;572627417.1299999952&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;highestPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;lowestPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.47&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;closePrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;negMarketValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;126303384220.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;marketValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;153102835340.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;isOpen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;secID&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;000001.XSHE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;listDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1991-04-03&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ListSector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\u4e3b\u677f&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;totalShares&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14308676200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ticker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;000002&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tradeDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2016-03-30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;exchangeCD&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;XSHE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;secShortName&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\u4e07\u79d1A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;preClosePrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;24.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;openPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dealAmount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;turnoverValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;highestPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;lowestPrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;closePrice&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;24.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;negMarketValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;237174448154.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;marketValue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;269685994760.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;isOpen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;secID&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;000002.XSHE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;listDate&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1991-01-29&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;ListSector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\u4e3b\u677f&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;totalShares&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;11039132000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### df is short for dataframe&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;hdfs://10.21.208.21:8020/user/mercury/stock_5.json&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;ticker&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;secID&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;tradeDate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;listDate&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;openPrice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;closePrice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;s&quot;&gt;&#39;highestPrice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;lowestPrice&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;isOpen&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-2.jpg&quot; alt=&quot;spark-dataframe-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;dataframe-1&quot;&gt;4. 操作 dataframe&lt;/h2&gt;

&lt;p&gt;同 rdd 一样，dataframe 也有很多专属于自己的算子，用于操作整个 dataframe 数据集，我们以后都简称为 dataframe api 吧，用 &lt;code class=&quot;highlighter-rouge&quot;&gt;算子&lt;/code&gt;， &lt;code class=&quot;highlighter-rouge&quot;&gt;DSL&lt;/code&gt; 这类的称呼对不熟悉的人来说不易理解，下面这里是完整的 api 列表：&lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame&quot;&gt;spark dataframe api&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;dataframe--sql-&quot;&gt;4.1 在 dataframe 上执行 sql 语句&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-4.jpg&quot; alt=&quot;spark-dataframe-4.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-dataframe--pandas-dataframe-&quot;&gt;4.2 spark dataframe 与 pandas dataframe 转换&lt;/h3&gt;

&lt;p&gt;一图胜千言啊：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-6.jpg&quot; alt=&quot;spark-dataframe-6.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;纵观 spark 的诞生和发展，我觉得 spark 有一点做得非常明智：&lt;em&gt;对同类产品的兼容&lt;/em&gt;。从大的方面来说，就像 spark 官网的这段话一样: &lt;em&gt;Runs Everywhere: Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3.&lt;/em&gt;，spark 对 hadoop 系产品的兼容，让 hadoop 系的开发人员可以轻松的从 hadoop 转到 spark；从小的方面来说，spark 对一些细分工具也照顾 [兼容] 得很好，比如说 spark 推出了 dataframe，人家就可以支持 spark dataframe 和 pandas dataframe 的转换。&lt;/p&gt;

&lt;p&gt;熟悉 pandas dataframe 的都了解，pandas 里的 dataframe 可以做很多事情，比如说画图，保存为各种类型的文件，做数据分析什么的。我觉得，可以在 spark 的 dataframe 里做数据处理，分析的整个逻辑，然后可以把最后的结果转化成 pandas 的 dataframe 来展示。当然，如果你的数据量小，也可以直接用 pandas dataframe 来做。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-dataframe-7.jpg&quot; alt=&quot;spark-dataframe-7.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;5. 一些经验&lt;/h2&gt;

&lt;h3 id=&quot;spark-json-&quot;&gt;5.1 spark json 格式问题&lt;/h3&gt;

&lt;p&gt;spark 目前也不支持读取标准的 json 文件。你需要预先把标准的 json 文件处理成 spark 支持的格式: 每一行是一个 json 对象。&lt;/p&gt;

&lt;h3 id=&quot;spark-dataframe--pandas-dataframe--1&quot;&gt;5.2 spark dataframe 和 pandas dataframe 选择问题&lt;/h3&gt;

&lt;p&gt;如果数据量小，结构简单，可以直接用 pandas dataframe 来做分析；如果数据量大，结构复杂 [嵌套结构]，那么推荐用 spark dataframe 来做数据分析，然后把结果转成 pandas dataframe，用 pandas dataframe 来做展示和报告。&lt;/p&gt;

&lt;h2 id=&quot;next&quot;&gt;6. Next&lt;/h2&gt;

&lt;p&gt;ok，dataframe 简单的也说了几句了。我们先缓一缓，上个例子，再接着讲起他的，例子的话就用一个我正在实践的：用 spark 来做量化投资。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;7. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes&quot;&gt;Spark SQL, DataFrames and Datasets Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html&quot;&gt;Introducing DataFrames in Spark for Large Scale Data Science&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.databricks.com/questions/7257/from-webinar-spark-dataframes-what-is-the-differen-1.html&quot;&gt;From Webinar Apache Spark 1.5: What is the difference between a DataFrame and a RDD?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/apache-spark-sql&quot;&gt;用Apache Spark进行大数据处理——第二部分：Spark SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/02/an-introduction-to-json-support-in-spark-sql.html&quot;&gt;An introduction to JSON support in Spark SQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.csdn.net/article/2015-02-18/2823997&quot;&gt;Spark新年福音：一个用于大规模数据科学的API——DataFrame&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2015/02/02/an-introduction-to-json-support-in-spark-sql.html&quot;&gt;An introduction to JSON support in Spark SQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>『 读书笔记 』3月读书总结和推荐</title>
     <link href="/books-recommend-and-summarize-on-mar-2016"/>
     <updated>2016-03-26T00:00:00+08:00</updated>
     <id>/books-recommend-and-summarize-on-mar-2016</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;计划是每月读 5-10 本书，书籍类型大概是三个方面的：金融，技术，管理。之所以选择这三个方面，一方面是因为自己对这三个方面都很有兴趣，其次是被 linkedin 创始人 Hoffman 的 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;ABZ 理论&lt;/a&gt; 深度影响。建议大家都看看 abz 理论那篇文章，如果我有空，也会整理一些常用的这类理论模型到博客里的。&lt;/p&gt;

&lt;p&gt;月底读书总结的形式都很简单，只是简单的一个列表和简单的书评，对觉得比较好的书会有单独的读书笔记。另外推荐大家用 excel 来做一些简单的工作管理，我现在就用 google docs 来做工作安排和读书计划，个人感觉比一些常用的神马协同软件强大太多了，简单，够用，就行了。工作中见过太多人把时间都花到使用那些协同软件上去，不得不说避重就轻了，适得其反，哈哈。&lt;/p&gt;

&lt;p&gt;下面是一张我用 google docs 来做读书安排的截图，不同颜色代表不同类别的数据，清晰明了实用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/book-reading.jpg&quot; alt=&quot;book-reading.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本月看了 7 本书，其中的电子书链接都放到亲爱的&lt;a href=&quot;http://pan.baidu.com/s/1pL26FZd&quot;&gt;度娘云&lt;/a&gt;里了，个人觉得不错的书都是纸板的，不知道有没有电子版的，推荐好书都看纸版的。&lt;/p&gt;

&lt;p&gt;ps: 我对好书的定义很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给自己有所启发的&lt;/li&gt;
  &lt;li&gt;高质量的，专业的教程类书籍&lt;/li&gt;
  &lt;li&gt;后期会再度回首的书&lt;/li&gt;
  &lt;li&gt;看完后会打算赠送给盆友看的书&lt;/li&gt;
  &lt;li&gt;留着给儿子看的书 [好吧，目前我只有个宝贝侄儿，哈哈]&lt;/li&gt;
  &lt;li&gt;最后一条，印刷质量要好&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;httppanbaiducoms1pl26fzd&quot;&gt;1. &lt;a href=&quot;http://pan.baidu.com/s/1pL26FZd&quot;&gt;中国顶尖技术团队访谈录 - 电子版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;这是 infoq 出的一系列电子书中的一本，总共有 4 季访谈录，都是对一些公司技术领导人的访谈，虽然访谈都讲得很粗，但是在遇到相关问题时也可以参考参考别人是怎么处理的，比如说当你要搭建一个大型 docker 集群时，可以参考参考第二季访谈录中这篇 &lt;em&gt;腾讯罗韩梅 :万台规模的 Docker 应用实践&lt;/em&gt; ，虽然说肯定不能解决你的所有问题，但是你肯定知道在腾讯有这样一个牛人有这个经验啊，去 linkedin 什么的找找这个人，邮件或者微信或者通过其他方式请教人家也行啊，是吧，哈哈。&lt;/p&gt;

&lt;p&gt;总结：不要奢求能从这系列访谈里学到降龙十八掌，但是对于一个 tech leader 来说，看看这些书是应该的，&lt;em&gt;书中自有颜如玉，书外自有黄金屋&lt;/em&gt;。btw，第三季和第四季做得没前两季好，页数都少了很多，估计是 infoq 不想做这个访谈了吧，anyway。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;python-for-finance---httppanbaiducoms1pl26fzd&quot;&gt;2. &lt;a href=&quot;http://pan.baidu.com/s/1pL26FZd&quot;&gt;python for finance - 电子版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;通读下来，这本书更应该叫 &lt;code class=&quot;highlighter-rouge&quot;&gt;python for finance - python tutoial and introduction to some basic financial theories&lt;/code&gt;，干货不多，大多数篇幅都去讲 &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt; 了，也讲了一些基础的金融理论，比如说蒙特卡罗模拟，期权定价原理什么的。如果你会 python，会用 pandas，懂一些基础的金融知识，可以不看这本书了。读下来对这本书没有什么大的感触，就不发表太多看法了。&lt;/p&gt;

&lt;p&gt;总结：如果你会 python，会用 pandas，懂一些基础的金融知识，可以不看这本书了；如果你不懂 python，不会 pandas，那也不推荐用这本书来学 python。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;etf----httppanbaiducoms1pl26fzd&quot;&gt;3. &lt;a href=&quot;http://pan.baidu.com/s/1pL26FZd&quot;&gt;etf 投资，从入门到精通 - 电子版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;之所以想看这本书，是一位大神觉得股票市场波动太大，去玩 etf 风险低，手续费也便宜，推荐我玩玩 etf。因为自己对 etf 一点不通，就买了这本书来看，上交所出版的，很专业，也讲得挺细致，对想玩，喜欢玩 etf 的人来说应该算是本好的手册。&lt;/p&gt;

&lt;p&gt;总结：etf 基础书籍里比较好的，对 etf 感兴趣的人可以看看哦。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;httpwwwamazoncne7bd97e8be91e6809de7bbb4-e69c89e7a78d-e69c89e8b6a3-e69c89e69699-e7bd97e68cafe5ae87dpb00fvha2f0refsr11ieutf8qid1459046888sr8-1keywordse980bbe8be91e6809de7bbb4&quot;&gt;4. &lt;a href=&quot;http://www.amazon.cn/%E7%BD%97%E8%BE%91%E6%80%9D%E7%BB%B4-%E6%9C%89%E7%A7%8D-%E6%9C%89%E8%B6%A3-%E6%9C%89%E6%96%99-%E7%BD%97%E6%8C%AF%E5%AE%87/dp/B00FVHA2F0/ref=sr_1_1?ie=UTF8&amp;amp;qid=1459046888&amp;amp;sr=8-1&amp;amp;keywords=%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4&quot;&gt;罗辑思维:有种、有趣、有料 - 纸版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;罗辑思维出了几本书了，我看的是第一本，很有意思。不仅是观点上新颖独到，老罗还把网络上的一些评论也放到书里去了，甚至还放了一些&lt;code class=&quot;highlighter-rouge&quot;&gt;负面&lt;/code&gt;的评论，对读者来说这样很不错。读这本书，能让人在看待问题，处理问题时的思路更开阔，更宽容一些，学会从更多方面，更多角度去挖掘一个问题的根本原因。这本书还有个比较让我喜欢的地方，每章都会有一些推荐的书，其中不乏好书。经常听到人说很想看书，但是不知道看什么书，对此我的回答的 “随便挑本书来看，看着看着就知道该看什么书了”。还准备看看之后的版本，虽然同事说后面的版本没有前面的有意思了，不过打算先去书店翻看翻看，如果后续的版本不是换汤不换药，仍然满足上面我对好书的定义，那我也会毫不犹豫的买纸版来看的。&lt;/p&gt;

&lt;p&gt;总结：比较适合学生，职场人士读的书，尝试学会从更多的方面去待人待物。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;httppanbaiducoms1pl26fzd-1&quot;&gt;5. &lt;a href=&quot;http://pan.baidu.com/s/1pL26FZd&quot;&gt;从0到1 - 电子版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;这本书曾经很火，还记得当时公司群里时常都在讨论。虽然我看的是电子版的，不过我也觉得这本书值得买纸版的，如果能容忍那外强中干的印刷质量的话。这本书单独有总结帖的：&lt;/p&gt;

&lt;p&gt;总结：很适合工作 3 年以上的人看，特别是想创业，创业中的，在创业公司上班的人，以创业心态工作的人看。或者再宽泛一点，适合想把事情做好的人看。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;httpwwwamazoncne69cbae599a8e5ada6e4b9a0-e591a8e5bf97e58d8edpb01arkev1grefsr11ieutf8qid1459046918sr8-1keywordse69cbae599a8e5ada6e4b9a0&quot;&gt;6. &lt;a href=&quot;http://www.amazon.cn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%91%A8%E5%BF%97%E5%8D%8E/dp/B01ARKEV1G/ref=sr_1_1?ie=UTF8&amp;amp;qid=1459046918&amp;amp;sr=8-1&amp;amp;keywords=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&quot;&gt;机器学习（周志华）- 纸版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;啊哈，这本书怎么说呢？之所以买他全是因为同事朋友圈里的一篇转发，说这个似乎是泰斗级的教授写了一本机器学习的书，当时也看了下这个教授的介绍 &lt;em&gt;[&lt;/em&gt; 哈哈，对天朝的老师们没什么好感。按照我的理解，所谓 &lt;code class=&quot;highlighter-rouge&quot;&gt;师者，传道，授业，解惑也&lt;/code&gt;，不知道天朝有几个老师敢读了韩愈的这段话还敢自称师者的 &lt;em&gt;]&lt;/em&gt;，觉得还行，amazon 上的书评也还可以，就剁手买了下来。&lt;/p&gt;

&lt;p&gt;读下来，只能说还可以吧，just so so，但是这本书有种很浓烈的味道 －－ 书生味。也许是工作的原因，对这类有太多书生味的书没太大感觉。还是更喜欢实在一些的书，比如 Mitchell 的 《Machine Learning》, 图灵出版的《Machine Learning in Action》，或者细分下来的《推荐系统实战》这类书。&lt;/p&gt;

&lt;p&gt;总结：书生味太浓，内容倒是也不差。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;httpwwwamazoncne4bcb0e580bce79a84e889bae69caf-110e4b8aae8a7a3e8afbbe6a188e4be8b-e5b0bce58fa4e68b89e696afc2b7e696afe5af86e5beb7e69e97dpb014d1mc5wrefsr11ieutf8qid1459046933sr8-1keywordse4bcb0e580bce79a84e889bae69caf&quot;&gt;7. &lt;a href=&quot;http://www.amazon.cn/%E4%BC%B0%E5%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-110%E4%B8%AA%E8%A7%A3%E8%AF%BB%E6%A1%88%E4%BE%8B-%E5%B0%BC%E5%8F%A4%E6%8B%89%E6%96%AF%C2%B7%E6%96%AF%E5%AF%86%E5%BE%B7%E6%9E%97/dp/B014D1MC5W/ref=sr_1_1?ie=UTF8&amp;amp;qid=1459046933&amp;amp;sr=8-1&amp;amp;keywords=%E4%BC%B0%E5%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF&quot;&gt;估值的艺术:110个解读案例 - 纸版&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;和这本书的第一次相遇是在陆家嘴正大广场的书店里看到的，当时我很想找一本公司基本面的书来看看，准备在自己的投资模型里多加一些公司基本面的因子。当时第一次看到这本书，翻看了十来分钟，知道这就是我想要的，简单，够用，还有翔实的例子，比《公司财务原理》这类书要来得痛快干脆，btw，我并不是说《公司财务原理》这本书不好，我也在看这本书的，只是《估值的艺术》这本书更适合当时的需求。而且，从小的方面来说，这本书能教你一些公司基本面的东西，对投资有所帮助；从大到方面来说，这本书教你怎么挖掘一个潜力公司，或者教你怎么管理自己的公司，或者说教你当你有了自己的公司的时候，应该从哪些方面实时查看自己公司的发展情况。很有价值。&lt;/p&gt;

&lt;p&gt;总结：如果你做股票投资，这本书值得一看；如果你有自己的公司，或者以后想要有自己的公司，那这本书更值得反复品读。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;master-apache-sparkhttpswwwgitbookcombookjaceklaskowskimastering-apache-sparkdetails&quot;&gt;8. &lt;a href=&quot;https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details&quot;&gt;Master Apache Spark&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;这本书是一个国外咨询师写的开源书籍，居然还有一本纸质版的 &lt;a href=&quot;http://shop.oreilly.com/product/9781783987146.do&quot;&gt;Master Apache Spark&lt;/a&gt;，不过和这本开源书籍应该没什么关系。之所以想先看这本书是因为 spark 更新得很快，作者应该会及时更新相关内容到最新的 spark 版本。看下来感觉还行，都是作者根据相关文档，相关书籍，以及自己的理解和实践来写的。但是里面还是有一些问题，也有的地方没有写。不推荐作为第一本学习spark的书籍，可以在有一定经验后翻翻看。下月还是准备看 Matei 合写的 &lt;a href=&quot;http://shop.oreilly.com/product/0636920028512.do&quot;&gt;Learning Spark&lt;/a&gt;，虽然出版时间很早，但是毕竟是 spark 的作者参与的，内容应该更清晰，深入，等待下个月我的读书笔记吧。&lt;/p&gt;

&lt;p&gt;总结：内容还行，作者更新也挺频繁的，但是不推荐作为第一本学习 spark 的书，有一定经验后可以看看。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;In Startups And Life, You Need Plan A, B, And Z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task</title>
     <link href="/deep-into-spark-exection-model"/>
     <updated>2016-03-18T00:00:00+08:00</updated>
     <id>/deep-into-spark-exection-model</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;spark-&quot;&gt;1. spark 运行原理&lt;/h2&gt;

&lt;p&gt;这一节是本文的核心，我们可以先抛出一个问题，如果看完这一节，或者这一章之后，你能理解你的整个 spark 应用的执行流程，那就可以关掉这个网页了［对了，关掉网页之前记得分享一下哦，哈哈］&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Problem: How does user program get translated into units of physical execution ?&lt;/code&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们用一个例子来说明，结合例子和运行截图来理解。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1.1 例子，美国 1880 － 2014 年新生婴儿数据统计&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;目标&lt;/code&gt;：用美国 1880 － 2014 年新生婴儿的数据来做做简单的统计&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;数据源&lt;/code&gt;：&lt;a href=&quot;https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data&quot;&gt; https://catalog.data.gov&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;数据格式&lt;/code&gt;：
    &lt;ul&gt;
      &lt;li&gt;每年的新生婴儿数据在一个文件里面&lt;/li&gt;
      &lt;li&gt;每个文件的每一条数据格式：&lt;code class=&quot;highlighter-rouge&quot;&gt;姓名,性别,新生人数&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-data-format.jpg&quot; alt=&quot;baby-data-format.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;代码和结果展示&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;### packages&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### spark UDF (User Defined Functions)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;map_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### spark logic&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wholeTextFiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;hdfs://10.21.208.21:8020/user/mercury/names&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                        &lt;span class=&quot;n&quot;&gt;minPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  \
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map_extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;,&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt; \
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduceByKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### result displaying&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;birth&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
         &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;year&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;birth&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;US Baby Birth Data from 1897 to 2014&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_axis_bgcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;white&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;gray&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;y&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-1.jpg&quot; alt=&quot;baby-name-1.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;1.2 运行流程概览&lt;/h2&gt;

&lt;p&gt;还记得我们在  &lt;a href=&quot;../spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt; 讲到的构建一个 spark application 的过程吗：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;加载数据集&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;处理数据&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;结果展示&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面的 22 行代码，就已经把构建一个 spark app 的三大步骤完成了，amazing, right? 今天我们主要讲 spark 的运行逻辑，所以我们就以核心的 11 － 16 ，这六行代码来作为今天的主线，了解了解 spark 的原理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-2.jpg&quot; alt=&quot;baby-name-2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，整个逻辑实际上就用了 sparkContext 的一个函数，rdd 的 3 个 transformation 和 1 个 action。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-job.jpg&quot; alt=&quot;baby-name-job.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在让我们从 WEB UI 上来看看，当我们运行这段代码的时候，后台都发生了什么。
可以看到，执行这段代码的时候，spark 通过分析，优化代码，知道这段代码需要一个 job 来完成，所以 web ui 上只有一个 job。值得深究的是，这个 job 由两个 stage 完成，这两个 state 一共有 66 个 task。&lt;/p&gt;

&lt;p&gt;所以，这里我们就再次理解下 spark 里，job，stage，task 的概念：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;job&lt;/em&gt; : A job is triggered by an action, like count() or saveAsTextFile(). Click on a job to see information about the stages of tasks inside it. 理解了吗，所谓一个 job，就是由一个 rdd 的 action 触发的动作，可以简单的理解为，当你需要执行一个 rdd 的 action 的时候，会生成一个 job。&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;stage&lt;/em&gt; : stage 是一个 job 的组成单位，就是说，一个 job 会被切分成 1 个或 1 个以上的 stage，然后各个 stage 会按照执行顺序依次执行。至于 job 根据什么标准来切分 stage，可以回顾第二篇博文：&lt;a href=&quot;../spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;task&lt;/em&gt; : A unit of work within a stage, corresponding to one RDD partition。即 stage 下的一个任务执行单元，一般来说，一个 rdd 有多少个 partition，就会有多少个 task，因为每一个 task 只是处理一个 partition 上的数据。从 web ui 截图上我们可以看到，这个 job 一共有 2 个 stage，66 个 task，平均下来每个 stage 有 33 个 task，相当于每个 stage 的数据都有 33 个 partition [注意：这里是平均下来的哦，并不都是每个 stage 有 33 个 task，有时候也会有一个 stage 多，另外一个 stage 少的情况，就看你有没有在不同的 stage 进行 repartition 类似的操作了。]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-ui-1.jpg&quot; alt=&quot;baby-name-ui-1.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;job&quot;&gt;1.3 运行流程之 : job&lt;/h2&gt;

&lt;p&gt;根据上面的截图和再次重温，我们知道这个 spark 应用里只有一个 job，那就是因为我们执行了一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;collect&lt;/code&gt; 操作，即把处理后的数据全部返回到我们的 driver 上，进行后续的画图，返回的数据如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-3.jpg&quot; alt=&quot;baby-name-3.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;stage&quot;&gt;1.4 运行流程之 : stage&lt;/h2&gt;

&lt;p&gt;我们这个 spark 应用，生成了一个 job，这个 job 由 2 个 stage 组成，并且每个 stage 都有 33 个task，说明每个 stage 的数据都在 33 个 partition 上，这下我们就来看看，这两个 stage 的情况。&lt;/p&gt;

&lt;p&gt;首先，我们先看看为什么这里会有两个 stage，根据 &lt;a href=&quot;../spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt; 中对 stage 的描述，目前有两个划分 stage 的标准：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当触发 rdd 的 action 时 : 在我们的应用中就是最后的 &lt;code class=&quot;highlighter-rouge&quot;&gt;collect&lt;/code&gt; 操作，关于这个操作的说明，可以看官方文档: &lt;a href=&quot;https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collect&quot;&gt;rdd.collect&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;当触发 rdd 的 shuffle 操作时 : 在我们的应用中就是 &lt;code class=&quot;highlighter-rouge&quot;&gt;reduceByKey&lt;/code&gt; 这个操作，官方文档: &lt;a href=&quot;https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey&quot;&gt;rdd.reduceByKey&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-4.jpg&quot; alt=&quot;baby-name-4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再次回顾上面那张图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-job.jpg&quot; alt=&quot;baby-name-job.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这下应该就明了了，关于两个 stage 的情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-5.jpg&quot; alt=&quot;baby-name-5.jpg&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;第一个 stage，即截图中 stage id 为 0 的 stage，其执行了 &lt;code class=&quot;highlighter-rouge&quot;&gt;sc.wholeTextFiles().map().flatMap().map().reduceByKey()&lt;/code&gt; 这几个步骤，因为这是一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle&lt;/code&gt; 操作，所以后面会有 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Read&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Write&lt;/code&gt;。具体来说，就是在 stage 0 这个 stage 中，发生了一个 Shuffle 操作，这个操作读入 22.5 MB 的数据，生成 41.7 KB 的数据，并把生成的数据写在了硬盘上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第二个 stage，即截图中 stage id 为 1 到 stage，其执行了 &lt;code class=&quot;highlighter-rouge&quot;&gt;collect()&lt;/code&gt; 这个操作，因为这是一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;action&lt;/code&gt; 操作，并且它上一步是一个 Shuffle 操作，且没有后续操作，所以这里 &lt;code class=&quot;highlighter-rouge&quot;&gt;collect()&lt;/code&gt; 这个操作被独立成一个 stage 了。这里它把上一个 Shuffle 写下的数据读取进来，然后一起返回到 driver 端，所以这里可以看到他的 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shuffle Read&lt;/code&gt; 这里刚好读取了上一个 stage 写下的数据。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;task&quot;&gt;1.5 运行流程之 : task&lt;/h2&gt;

&lt;p&gt;其实到这里应该都理解得差不多了，至于为什么每个 stage 会有 33 个 task [即我们的数据文件存放到 33 个partition 上，可是明明 &lt;code class=&quot;highlighter-rouge&quot;&gt;sc.wholeTextFiles(&#39;hdfs://10.21.208.21:8020/user/mercury/names&#39;, minPartitions=40)&lt;/code&gt; 这里指定了最小要 40 个partition 到啊]，这个问题我们留到以后说，在后面我们会有一篇讲怎么调试，优化 spark app 的博文，到时候我们会继续回到这里，解答这里的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/baby-name-7.jpg&quot; alt=&quot;baby-name-7.jpg&quot; /&gt;
&lt;img src=&quot;../images/baby-name-8.jpg&quot; alt=&quot;baby-name-8.jpg&quot; /&gt;
&lt;img src=&quot;../images/baby-name-9.jpg&quot; alt=&quot;baby-name-9.jpg&quot; /&gt;
&lt;img src=&quot;../images/baby-name-10.jpg&quot; alt=&quot;baby-name-10.jpg&quot; /&gt;
&lt;img src=&quot;../images/baby-name-11.jpg&quot; alt=&quot;baby-name-11.jpg&quot; /&gt;
&lt;img src=&quot;../images/baby-name-12.jpg&quot; alt=&quot;baby-name-12.jpg&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;next&quot;&gt;2. Next&lt;/h2&gt;

&lt;p&gt;既然我们都慢慢开始深入理解 spark 的执行原理了，那下次我们就来说说 spark 的一些配置吧，然后再说说 spark 应用的优化。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;7. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/pwendell/tuning-and-debugging-in-apache-spark&quot;&gt;Tuning and Debugging in Apache Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/Learning-Spark-Lightning-Fast-Data-Analysis/dp/1449358624/ref=sr_1_1?ie=UTF8&amp;amp;qid=1458293667&amp;amp;sr=8-1&amp;amp;keywords=learning+spark&quot;&gt;learning spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aiyanbo.gitbooks.io/spark-programming-guide-zh-cn/content/more/spark-configuration.html&quot;&gt;Spark配置&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://colobu.com/2014/12/10/spark-configuration/&quot;&gt;Spark 配置指南&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-5&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>『 Spark 』5. 这些年，你不能错过的 spark 学习资源</title>
     <link href="/spark-resouces-blogs-paper"/>
     <updated>2016-03-10T00:00:00+08:00</updated>
     <id>/spark-resouces-blogs-paper</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。   &lt;br /&gt;
Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 书籍&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.cn/Spark%E5%BF%AB%E9%80%9F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E7%BE%8E-%E5%8D%A1%E5%8A%B3-%E7%BE%8E-%E8%82%AF%E7%BB%B4%E5%B0%BC%E6%96%AF%E7%A7%91-%E7%BE%8E-%E6%B8%A9%E5%BE%B7%E5%B0%94-%E5%8A%A0-%E6%89%8E%E5%93%88%E9%87%8C%E4%BA%9A/dp/B016DWSEXI/ref=sr_1_1?ie=UTF8&amp;amp;qid=1460447269&amp;amp;sr=8-1&amp;amp;keywords=spark+%E5%BF%AB%E9%80%9F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot;&gt;Learning Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details&quot;&gt;Mastering Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 网站&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/&quot;&gt;official site&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://apache-spark-user-list.1001560.n3.nabble.com/&quot;&gt;user mailing list&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/user/TheApacheSpark&quot;&gt;spark channel on youtube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://spark-summit.org/&quot;&gt;spark summit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.meetup.com/&quot;&gt;meetup&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark-packages.org/&quot;&gt;spark third party packages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog&quot;&gt;databricks blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html#Introduction%20(Readme).html&quot;&gt;databricks docs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.cloud.databricks.com/docs/latest/courses/index.html#Introduction%20to%20Big%20Data%20with%20Apache%20Spark%20(CS100-1x)/Introduction%20(README).html&quot;&gt;databricks training&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/spark/&quot;&gt;cloudera blog about spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://0x0fff.com&quot;&gt;https://0x0fff.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://techsuppdiva.github.io/&quot;&gt;http://techsuppdiva.github.io/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lib.csdn.net/base/10&quot;&gt;csdn spark 知识库&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.iteblog.com/archives/category/spark&quot;&gt;过往记忆&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 文章，博客&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf&quot;&gt;RDD论文英文版&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://code.csdn.net/CODE_Translation/spark_matei_phd&quot;&gt;RDD论文中文版&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-12.pdf&quot;&gt;An Architecture for Fast and General Data Processing
on Large Clusters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/&quot;&gt;How-to: Tune Your Apache Spark Jobs (Part 1)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/&quot;&gt;How-to: Tune Your Apache Spark Jobs (Part 2)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dataunion.org/22985.html&quot;&gt;借助 Redis ，让 Spark 提速 45 倍！&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.csdn.net/article/2015-10-06/2825849&quot;&gt;量化派基于Hadoop、Spark、Storm的大数据风控架构&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://geek.csdn.net/news/detail/58867&quot;&gt;基于Spark的异构分布式深度学习平台&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.36dsj.com/archives/40723&quot;&gt;你对Hadoop和Spark生态圈了解有几许？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.yuntoutiao.com/dongtai/5389.html&quot;&gt;Hadoop vs Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://geek.csdn.net/news/detail/57656&quot;&gt;雅虎开源CaffeOnSpark：基于Hadoop/Spark的分布式深度学习&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/files/1. spark_meetup.pdf&quot;&gt;2016 上海第二次 spark meetup: 1. spark_meetup.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/files/2. Flink_ An unified stream engine.pdf&quot;&gt;2016 上海第二次 spark meetup: 2. Flink_ An unified stream engine.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/files/3. Spark在计算广告领域的应用实践.pdf&quot;&gt;2016 上海第二次 spark meetup: 3. Spark在计算广告领域的应用实践.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/files/4. splunk_spark.pdf&quot;&gt;2016 上海第二次 spark meetup: 4. splunk_spark.pdf&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://prezi.com/w4wjzdq7y0lj/spark/&quot;&gt;基于Spark的医疗和金融大数据&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.hammerlab.org/2015/02/27/monitoring-spark-with-graphite-and-grafana/&quot;&gt;Monitoring Spark with Graphite and Grafana&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4. 视频&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=cs3_3LdCny8&quot;&gt;YouTube: what is apache spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=65aV15uDKgA&quot;&gt;Introduction to Spark Architecture&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=WyfHUNnMutg&quot;&gt;Top 5 Mistakes When Writing Spark Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/hadooparchbook/top-5-mistakes-when-writing-spark-applications&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Top 5 mistakes when writing Spark applications&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kkOG_aJ9KjQ&quot;&gt;Tuning and Debugging Apache Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/pwendell/tuning-and-debugging-in-apache-spark&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Tuning and Debugging Apache Spark&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dmL0N3qfSc8&quot;&gt;A Deeper Understanding of Spark Internals - Aaron Davidson (Databricks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://spark-summit.org/2014/wp-content/uploads/2014/07/A-Deeper-Understanding-of-Spark-Internals-Aaron-Davidson.pdf&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; A Deeper Understanding of Spark Internals - Aaron Davidson (Databricks)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=OednhGRp938&quot;&gt;Building, Debugging, and Tuning Spark Machine Learning Pipelines - Joseph Bradley (Databricks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/SparkSummit/building-debugging-and-tuning-spark-machine-leaning-pipelinesjoseph-bradley&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Building, Debugging, and Tuning Spark Machine Learning Pipelines&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=xWkJCUcD55w&quot;&gt;Spark DataFrames Simple and Fast Analysis of Structured Data - Michael Armbrust (Databricks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/spark-dataframes-simple-and-fast-analytics-on-structured-data-at-spark-summit-2015&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Spark DataFrames Simple and Fast Analysis of Structured Data - Michael Armbrust (Databricks)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=HBZuB3pPri0&amp;amp;feature=youtu.be&quot;&gt;Spark Tuning for Enterprise System Administrators&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/AnyaBida/bida-sse2016final-58237248&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Spark Tuning for Enterprise System Administrators&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=i7l3JQRx7Qw&quot;&gt;Structuring Spark: DataFrames, Datasets, and Streaming&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/structuring-spark-dataframes-datasets-and-streaming&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Structuring Spark: DataFrames, Datasets, and Streaming&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=GzG9RTRTFck&quot;&gt;Spark in Production: Lessons from 100+ Production Users&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/spark-summit-eu-2015-lessons-from-300-production-users&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Spark in Production: Lessons from 100+ Production Users&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=rBrsxM091KA&quot;&gt;Production Spark and Tachyon use Cases&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/SparkSummit/using-spark-with-tachyon-by-gene-pang&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Production Spark and Tachyon use Cases&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=VQOKk9jJGcw&amp;amp;index=5&amp;amp;list=PL-x35fyliRwif48cPXQ1nFM85_7e200Jp&quot;&gt;SparkUI Visualization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/spark-summit-eu-2015-sparkui-visualization-a-lens-into-your-application&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; SparkUI Visualization&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Wg2boMqLjCg&quot;&gt;
Everyday I’m Shuffling - Tips for Writing Better Spark Programs, Strata San Jose 2015&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs&quot;&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Everyday I’m Shuffling - Tips for Writing Better Spark Programs, Strata San Jose 2015&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=FA3ArTyXNoo&quot;&gt;Large Scale Distributed Machine Learning on Apache Spark&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Aups6UcGiQQ&amp;amp;list=PL-x35fyliRwif48cPXQ1nFM85_7e200Jp&amp;amp;index=1&quot;&gt;Securing your Spark Applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/cloudera/securing-your-apache-spark-applications&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Securing your Spark Applications&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AHYq91i-ohI&quot;&gt;Building a REST Job Server for Interactive Spark as a Service&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/SparkSummit/building-a-rest-job-server-for-interactive-spark-as-a-service-by-romain-rigaux-and-erick-tryzelaar&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Building a REST Job Server for Interactive Spark as a Service&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PPQRi484bNo&amp;amp;list=PL-x35fyliRwif48cPXQ1nFM85_7e200Jp&amp;amp;index=2&quot;&gt;Exploiting GPUs for Columnar DataFrame Operations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/SparkSummit/exploiting-gpus-for-columnar-datafrrames-by-kiran-lonikar&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Exploiting GPUs for Columnar DataFrame Operations&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=MFSUAkDBSdQ&quot;&gt;Easy JSON Data Manipulation in Spark - Yin Huai (Databricks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://spark-summit.org/2014/wp-content/uploads/2014/07/Easy-json-Data-Manipulation-Yin-Huai.pdf&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Easy JSON Data Manipulation in Spark - Yin Huai (Databricks)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8hn2KVC8FvA&amp;amp;index=6&amp;amp;list=PL-x35fyliRwiuc6qy9z2erka2VX8LY53x&quot;&gt;Sparkling: Speculative Partition of Data for Spark Applications - Peilong Li&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://spark-summit.org/2014/wp-content/uploads/2014/07/Sparkling-Indentification-of-Task-Skew-and-Speculative-Partition-of-Data-for-Spark-Applications-Peilong-Li.pdf&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Sparkling: Speculative Partition of Data for Spark Applications - Peilong Li&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=HG2Yd-3r4-M&amp;amp;list=PLTPXxbhUt-YWGNTaDj6HSjnHMxiTD1HCR&amp;amp;index=1&quot;&gt;Advanced Spark Internals and Tuning – Reynold Xin&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://databricks-training.s3.amazonaws.com/slides/advanced-spark-training.pdf&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Advanced Spark Internals and Tuning – Reynold Xin&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=oXkxXDG0gNk&quot;&gt;The Future of Real Time in Spark&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/the-future-of-realtime-in-spark-58433411&quot;&gt;The Future of Real Time in Spark&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZFBgY0PwUeY&amp;amp;feature=youtu.be&quot;&gt;Spark 2 0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/2016-spark-summit-east-keynote-matei-zaharia&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Spark 2 0&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=BPotQuqFnyw&amp;amp;feature=youtu.be&quot;&gt;Democratizing Access to Data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/2016-spark-summit-east-keynote-ali-ghodsi-and-databricks-community-edition-demo&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Democratizing Access to Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;next&quot;&gt;5. next&lt;/h2&gt;

&lt;p&gt;上面的资源我都会不断更新的，里面 80% 以上的都是我亲自看过并且觉得有价值的，可不是胡乱收集一通的，推荐欣赏哦。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;6. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay.png&quot; alt=&quot;wechat_pay.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   

</feed>



  <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1258855744'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1258855744' type='text/javascript'%3E%3C/script%3E"));
  </script>

</body>
</html>
