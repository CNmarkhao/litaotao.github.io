<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>『 Spark 』7. 使用 Spark DataFrame 进行大数据分析 | Taotao's Zone</title>
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile.css" type="text/css" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
</head>
<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    background: #333333;
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  /*body { background:transparent;}*/
  @media screen and (max-width: 750px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/2.jpg');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/spark-dataframe-introduction" title="『 Spark 』7. 使用 Spark DataFrame 进行大数据分析">『 Spark 』7. 使用 Spark DataFrame 进行大数据分析</a></h1>

    <p class="entry-date">2016-03-30 <span class="lastModified" style="display: none;" data-source="_posts/new-spark/2016-03-30-spark-dataframe-introduction.md">最后更新时间: </span></p>


    <h2 id="section">写在前面</h2>

<p>本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，并非为了做什么教程，所以一切以个人理解梳理为主，没有必要的细节就不会记录了。若想深入了解，最好阅读参考文章和官方文档。</p>

<p>其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本好还是必要的。</p>

<p>Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦。</p>

<h2 id="spark-dataframe">1. 什么是 spark dataframe</h2>

<p>先来看看官方原汁原味的文档是怎么介绍的：</p>

<p>A DataFrame is <code class="highlighter-rouge">a distributed collection of data</code> organized into named columns. It is conceptually equivalent to a <code class="highlighter-rouge">table in a relational database</code> or a data frame in R/Python, but with <code class="highlighter-rouge">richer optimizations</code> under the hood. DataFrames can be constructed from a wide array of sources such as: <code class="highlighter-rouge">structured data files, tables in Hive, external databases, or existing RDDs</code>.</p>

<p>我们可以看到 spark dataframe 的几个关键点：</p>

<ul>
  <li>分布式的数据集</li>
  <li>类似关系型数据库中的table，或者 excel 里的一张 sheet，或者 python/R 里的 dataframe</li>
  <li>拥有丰富的操作函数，类似于 rdd 中的算子</li>
  <li>一个 dataframe 可以被注册成一张数据表，然后用 sql 语言在上面操作</li>
  <li>丰富的创建方式
    <ul>
      <li>已有的RDD</li>
      <li>结构化数据文件</li>
      <li>JSON数据集</li>
      <li>Hive表</li>
      <li>外部数据库</li>
    </ul>
  </li>
</ul>

<h2 id="spark-dataframe-1">2. 为什么要用 spark dataframe</h2>

<p>DataFrame API 是在 R 和 Python data frame 的设计灵感之上设计的，具有以下功能特性：</p>

<ul>
  <li>从KB到PB级的数据量支持；</li>
  <li>多种数据格式和多种存储系统支持；</li>
  <li>通过Spark SQL 的 Catalyst优化器进行先进的优化，生成代码；</li>
  <li>通过Spark无缝集成所有大数据工具与基础设施；</li>
  <li>为Python、Java、Scala和R语言（SparkR）API；</li>
</ul>

<p>简单来说，dataframe 能够更方便的操作数据集，而且因为其底层是通过 spark sql 的 Catalyst优化器生成优化后的执行代码，所以其执行速度会更快。总结下来就是，使用 spark dataframe 来构建 spark app，能：</p>

<ul>
  <li><em>write less : 写更少的代码</em></li>
  <li><em>do more : 做更多的事情</em></li>
  <li><em>faster : 以更快的速度</em></li>
</ul>

<h3 id="write-less--">2.1 write less : 写更少的代码</h3>

<h3 id="do-more--">2.2 do more : 做更多的事情</h3>

<h3 id="faster--">2.3 faster : 以更快的速度</h3>

<h2 id="dataframe">3. 创建 dataframe</h2>

<p>因为 spark sql，dataframe，datasets 都是共用 spark sql 这个库的，三者共享同样的代码优化，生成以及执行流程，所以 sql，dataframe，datasets 的入口都是 sqlContext.</p>

<ul>
  <li>step 1 : 创建 sqlContext</li>
</ul>

<p>下面是我自己创建 spark sc 都模版：</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">sc_conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span>
<span class="n">sc_conf</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="s">"03-DataFrame-01"</span><span class="p">)</span>
<span class="n">sc_conf</span><span class="o">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">SPARK_MASTER</span><span class="p">)</span>
<span class="n">sc_conf</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">'spark.executor.memory'</span><span class="p">,</span> <span class="s">'2g'</span><span class="p">)</span>
<span class="n">sc_conf</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">'spark.logConf'</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sc_conf</span><span class="o">.</span><span class="n">getAll</span><span class="p">()</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">sc_conf</span><span class="p">)</span>
    <span class="n">sqlContext</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>step 2 : 创建 dataframe，从已有的 RDD</li>
</ul>

<h2 id="dataframe-1">4. 操作 dataframe</h2>

<h2 id="section-1">5. 一些经验</h2>

<h2 id="next">2. Next</h2>

<p>既然我们都慢慢开始深入理解 spark 的执行原理了，那下次我们就来说说 spark 的一些配置吧，然后再说说 spark 应用的优化。</p>

<h2 id="section-2">参考文章</h2>

<ul>
  <li><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes">Spark SQL, DataFrames and Datasets Guide</a></li>
  <li><a href="https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html">Introducing DataFrames in Spark for Large Scale Data Science</a></li>
</ul>

<h2 id="section-3">本系列文章链接</h2>

<ul>
  <li><a href="../introduction-to-spark">『 Spark 』1. spark 简介 </a></li>
  <li><a href="../spark-questions-concepts">『 Spark 』2. spark 基本概念解析 </a></li>
  <li><a href="../spark-programming-model">『 Spark 』3. spark 编程模式 </a></li>
  <li><a href="../spark-what-is-rdd">『 Spark 』4. spark 之 RDD </a></li>
  <li><a href="../spark-resouces-blogs-paper">『 Spark 』5. 这些年，你不能错过的 spark 学习资源 </a></li>
  <li><a href="deep-into-spark-exection-model">『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task</a></li>
</ul>



    <!-- share icon -->
    <div class="ds-share" data-thread-key="/spark-dataframe-introduction" data-title="『 Spark 』7. 使用 Spark DataFrame 进行大数据分析"
         data-content="content"
         data-url="http://litaotao.github.io//spark-dataframe-introduction">
        <div class="ds-share-aside-left">
          <div class="ds-share-aside-inner">
          </div>
          <div class="ds-share-aside-toggle">分享</div>
        </div>
    </div>

    <div id="disqus_container">
      <div style="margin-bottom:20px">
      <!-- 多说评论框 start -->
        <div class="ds-thread" data-thread-key=/spark-dataframe-introduction data-title=『 Spark 』7. 使用 Spark DataFrame 进行大数据分析 data-url=/spark-dataframe-introduction></div>
      <!-- 多说评论框 end -->
      <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"litaotao"};
        (function() {
          var ds = document.createElement('script');
          ds.type = 'text/javascript';ds.async = true;
          ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
          ds.charset = 'UTF-8';
          (document.getElementsByTagName('head')[0]
           || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
      <!-- 多说公共JS代码 end -->
      </div>
    </div>
  </div>

  <div id="menuIndex" class="sidenav">
    <div class="myinfo"><center>
      <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;"></div>
      <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
      <a href="http://www.linkedin.com/in/taotaoli"><i class="icon-linkedin-sign icon-large"></i><span> Profile</span></a>
      <a href="https://github.com/litaotao"><i class="icon-github icon-large"></i><span> Code</span></a>
      <a href="mailto:taotao.engineer@gmail.com"><i class="icon-envelope-alt icon-large"></i><span> Mail</span></a>
    </center></div>
    <div id="menu"></div>
  </div>
</div>


<script src="/js/post.js" type="text/javascript"></script>

</body>
</html>
