<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>［touch spark］2. Amazon AWS EC2 入门 | Taotao's Zone</title>
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile.css" type="text/css" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
</head>
<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    /*background: url() no-repeat center center fixed;*/
    background: #333333;
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  body { background:transparent; }
  @media screen and (max-width: 750px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/2.jpg');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/using-amazon-aws-1" title="［touch spark］2. Amazon AWS EC2 入门">［touch spark］2. Amazon AWS EC2 入门</a></h1>

    <p class="entry-date">2014-12-01 <span class="lastModified" style="display: none;" data-source="_posts/spark/2014-12-01-using-amazon-aws-1.md">最后更新时间: </span></p>

    <h2>1. 申请Amazon AWS账号</h2>

<p>　　申请Amazon AWS需要绑定信用卡，无奈兄弟我从来没用过信用卡，所以只能跑到<a href="https://www.globalcash.hk/">global cash</a>申请一张虚拟信用卡了。有关申请虚拟信用卡的教程<a href="http://www.freehao123.com/globalcash/">这里</a>已经有了，我就不重复了。<br>
　　需要注意的是，申请好AWS账号后，会需要一段时间验证，一般一天之内就可以正常使用了。在此期间可以做一些基本的设置，比如说设置安全证书。未完成验证之前使用一些组件，比如说EC2，S3等时会出现下面这样子的提示。如果出现这样子的提示，可以先看看文档，到处随便逛逛，等验证好了就可以用了。   </p>

<p><img src="../../images/learning-spark-13.jpg" alt="learning-spark-13">  </p>

<h2>2. 在EC2上创建一个spark集群</h2>

<h3>2.1 前期准备</h3>

<p>　　本文中用到的所有脚本都是基于python 2.x写的，且在Linux和0S X上测试通过。  </p>

<h3>2.2 创建AWS IAM，安全证书</h3>

<p>　　首先确保你的地区是US EAST，在右上角可以选择区域，即帐号名右侧。还没找到的请看下图：<br>
<img src="../../images/choose_ec2_region.png" alt="choose_ec2_region">  </p>

<p>　　然后在帐号名-&gt;Security Credentials-&gt;Dashboard 下的 Details-&gt;Security Status-&gt;Manage Security Credentials-&gt;Access Keys-&gt;Create New Access Key创建keys，这里最好把keys记录下来，以后好用。<br>
　　在与 AWS 交互时，使用 AWS 安全证书验证您的身份以及您是否有权访问请求的资源。换句话说，安全证书可用于验证和授权对 AWS 的调用。关于安全证书更多的讲解，可以参考<a href="http://docs.aws.amazon.com/zh_cn/general/latest/gr/aws-security-credentials.html">这篇文档</a>。<br>
　　设置变量，下面的KEY<em>ID, ACCESS</em>KEY是在你创建keys的时候产生的：</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">export AWS_ACCESS_KEY_ID=&lt;ACCESS_KEY_ID&gt;
export AWS_SECRET_ACCESS_KEY=&lt;SECRET_ACCESS_KEY&gt;
</code></pre></div>
<h3>2.3 创建key pair</h3>

<p>　　在EC2 Dashboard左侧边栏-&gt;Network &amp; Security-&gt;Key Pairs-&gt;Create Key Pair。这里会需要你输入一个key pair name，最好搞一个简单好记的，因为以后也会用到。创建成功后会自动下载一个用于后期验证登录的文件，下载该文件把其复制到用户家目录下，确保其权限至少是600，保险起见执行 chmod 600 key<em>pair</em>file。  </p>

<h3>2.4 下载启动脚本</h3>
<div class="highlight"><pre><code class="language-text" data-lang="text">git clone git://github.com/amplab/ampcamp.git  
</code></pre></div>
<h3>2.5 建立并启动集群</h3>

<p>　　若上面的启动脚本下载成功后，本地会有一个ampcamp的文件夹，cd 到ampcamp文件夹里，执行下面命令启动集群。其中key<em>file是刚刚下载并复制到家目录下的验证文件，name</em>of<em>key</em>pair是你创建key_pair的时候自己命名的。  </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">./spark-ec2 -i &lt;key_file&gt; -k &lt;name_of_key_pair&gt; --copy launch ampcamp
</code></pre></div>
<p>　　上面这个过程大约会持续15-20分钟，耐心等待一下。如果期间出现下面这个问题，那是因为没有把key_pair文件复制到家目录下去。</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">rsync: connection unexpectedly closed (0 bytes received so far) [sender]
rsync error: unexplained error (code 255) at io.c(605) [sender=3.0.9]
Traceback (most recent call last):
  File &quot;./spark_ec2.py&quot;, line 759, in &lt;module&gt;
    main()
  File &quot;./spark_ec2.py&quot;, line 648, in main
    setup_cluster(conn, master_nodes, slave_nodes, zoo_nodes, opts, True)
  File &quot;./spark_ec2.py&quot;, line 363, in setup_cluster
    deploy_files(conn, &quot;deploy.generic&quot;, opts, master_nodes, slave_nodes, zoo_nodes)
  File &quot;./spark_ec2.py&quot;, line 604, in deploy_files
    subprocess.check_call(command, shell=True)
  File &quot;/root/anaconda/lib/python2.7/subprocess.py&quot;, line 540, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command &#39;rsync -rv -e &#39;ssh -o StrictHostKeyChecking=no -i ../company.pem&#39; &#39;/tmp/tmp6YpLzV/&#39; &#39;root@ec2-54-172-219-206.compute-1.amazonaws.com:/&#39;&#39; returned non-zero exit status 255
root@ubuntu2:~/Desktop/spark/ampcamp# cp ../company.pem .
</code></pre></div>
<p>　　如果一切顺利（但愿），最后会有消息提示创建成功：SUCCESS: Cluster successfully launched! You can login to the master at ***</p>

<h3>2.6 其他相关命令</h3>

<p>　　第一个命令获取ampcamp集群的master节点，这个需要在集群启动成功后执行一次，因为后续也要用到这个节点地址，所以最好把master 节点地址记录下来。第二个命令是删除集群。    </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">./spark-ec2 -i &lt;key_file&gt; -k &lt;key_pair&gt; get-master ampcamp   
./spark-ec2 -i &lt;key_file&gt; -k &lt;key_pair&gt; destroy ampcamp  
</code></pre></div>
<h2>3. 查看集群设置和数据准备</h2>

<h3>3.1 获取master节点地址</h3>

<p>　　在这个练习中，我们会用从<a href="http://aws.amazon.com/datasets/4182">http://aws.amazon.com/datasets/4182</a>拿到的wikipedia的流量数据来做分析。<br>
　　方便起见，AMP Camp已经提前把(May 5 to May 7, 2009; roughly 20G and 329 million entries)的数据准备好，并且预加载到集群里一个HDFS机器上了。这样我们就不用准备数据了，可以专注在体验spark特性的这件事上。</p>

<h3>3.1 获取master节点地址</h3>
<div class="highlight"><pre><code class="language-text" data-lang="text">./spark-ec2 -i &lt;key_file&gt; -k &lt;key_pair&gt; get-master ampcamp  
</code></pre></div>
<p>　　此时成功的话应该会提示你当前有一个master，3个slave，0个ZooKeeper。  </p>

<h3>3.2 使用ssh登录master节点</h3>
<div class="highlight"><pre><code class="language-text" data-lang="text">ssh -i &lt;key_file&gt; -l root &lt;master_node_hostname&gt;
or
ssh -i &lt;key_file&gt; root &lt;master_node_hostname&gt;
</code></pre></div>
<p>　　需要注意的是，这里虽然你是登录到一个机器上，但实际是一个集群中。集群里有一个master节点，3个slave节点。其中你登录的地方是master节点，master节点主要负责任务分配和管理HDFS的元数据。其他的3个slave节点是计算节点，也就是真正运行任务的节点。<br>
　　在master里，执行ls可以看到以下几个文件夹，下面列出比较重要的几个文件夹：  </p>

<ul>
<li>ephemeral-hdfs: Hadoop installation<br></li>
<li>hive: Hive installation<br></li>
<li>java-app-template: Some stand-alone Spark programs in java<br></li>
<li>mesos: Mesos installation<br></li>
<li>mesos-ec2: A suite of scripts to manage Mesos on EC2<br></li>
<li>scala-2.9.1.final: Scala installation<br></li>
<li>scala-app-template: Some stand-alone Spark programs in scala<br></li>
<li>spark: Spark installation<br></li>
<li>shark: Shark installation<br></li>
</ul>

<p>　　可以在mesos-ec2/slaves文件里看到自己的3个slave节点地址：  </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[root@ip-172-31-22-240 ~]# cat mesos-ec2/slaves
ec2-54-174-175-127.compute-1.amazonaws.com
ec2-54-174-183-88.compute-1.amazonaws.com
ec2-54-174-124-52.compute-1.amazonaws.com
</code></pre></div>
<p>　　你的HDFS集群应该已经提前载入20GB的wikipedia数据文件了，可以到ephemeral-hdfs/bin/下执行hadoop fs -ls /wiki/pagecounts查看，这里应该是有74个文件，其中2个是空的。其中每一个文件是以小时为单位来保存的。  </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">[root@ip-172-31-22-240 ~]# ephemeral-hdfs/bin/hadoop fs -ls /wiki/pagecounts
Found 74 items
-rw-r--r--   3 root supergroup          0 2014-12-03 02:18 /wiki/pagecounts/part-00095
-rw-r--r--   3 root supergroup  244236879 2014-12-03 02:18 /wiki/pagecounts/part-00096
-rw-r--r--   3 root supergroup  233905016 2014-12-03 02:18 /wiki/pagecounts/part-00097
-rw-r--r--   3 root supergroup  225825888 2014-12-03 02:19 /wiki/pagecounts/part-00098
-rw-r--r--   3 root supergroup  225164279 2014-12-03 02:18 /wiki/pagecounts/part-00099
-rw-r--r--   3 root supergroup  228145848 2014-12-03 02:19 /wiki/pagecounts/part-00100
.            
.
.
-rw-r--r--   3 root supergroup  327382691 2014-12-03 02:26 /wiki/pagecounts/part-00163
-rw-r--r--   3 root supergroup  325471268 2014-12-03 02:27 /wiki/pagecounts/part-00164
-rw-r--r--   3 root supergroup  288288841 2014-12-03 02:27 /wiki/pagecounts/part-00165
-rw-r--r--   3 root supergroup  266179174 2014-12-03 02:29 /wiki/pagecounts/part-00166
-rw-r--r--   3 root supergroup  243451716 2014-12-03 02:18 /wiki/pagecounts/part-00167
-rw-r--r--   3 root supergroup          0 2014-12-03 02:19 /wiki/pagecounts/part-00168
</code></pre></div>
<p>　　其中，每个文件都以一行为单位记录，每行都符合模式：<code>&lt;date_time&gt; &lt;project_code&gt; &lt;page_title&gt; &lt;num_hits&gt; &lt;page_size&gt;</code>。其中<code>&lt;date_time&gt;</code>字段以YYYYMMDD-HHMMSS为时间格式，表示访问时间，且以小时为单位，所以只有YYYYMMDD-HH为有效数据，MMSS都为0，<code>&lt;project_code&gt;</code>字段表示对应的页面所使用的语言，如&quot;en&quot;则表示英文；<code>&lt;page_title&gt;</code>字段表示该页面在wiki上的标题，<code>&lt;num_hits&gt;</code>表示从<code>&lt;date_time&gt;</code>时间起一小时内的浏览量，<code>&lt;page_size&gt;</code>表示以字节为单位，这个页面的大小。</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">20090507-040000 aa Main_Page 7 51309
20090507-040000 aa Special:Boardvote 1 11631
20090507-040000 aa Special:Imagelist 1 931
</code></pre></div>
<p>　　下一篇会记录在EC2上用spark分析wikipedia流量的过程，请移步<a href="../using-amazon-aws-2">使用Spark分析wikipedia流量数据</a></p>

<h2>相关资料</h2>

<ul>
<li><a href="http://docs.aws.amazon.com/zh_cn/general/latest/gr/Welcome.html">AWS官方中文文档</a></li>
</ul>

<h2>扫一扫</h2>

<p><img src="../../images/share/2014-12-01-using-amazon-aws-1.md.jpg" alt="2014-12-01-using-amazon-aws-1.md"></p>


    <div id="disqus_container">
      <div style="margin-bottom:20px">
      <!-- 多说评论框 start -->
        <div class="ds-thread" data-thread-key=/using-amazon-aws-1 data-title=［touch spark］2. Amazon AWS EC2 入门 data-url=/using-amazon-aws-1></div>
      <!-- 多说评论框 end -->
      <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"litaotao"};
        (function() {
          var ds = document.createElement('script');
          ds.type = 'text/javascript';ds.async = true;
          ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
          ds.charset = 'UTF-8';
          (document.getElementsByTagName('head')[0] 
           || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
      <!-- 多说公共JS代码 end -->
      </div>
    </div>
  </div>

  <div id="menuIndex" class="sidenav">
    <div class="myinfo"><center>
      <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;"></div>
      <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
      <a href="http://www.linkedin.com/in/taotaoli"><i class="icon-linkedin-sign icon-large"></i><span> Profile</span></a>
      <a href="https://github.com/litaotao"><i class="icon-github icon-large"></i><span> Code</span></a>
      <a href="mailto:taotao.engineer@gmail.com"><i class="icon-envelope-alt icon-large"></i><span> Mail</span></a>
    </center></div>
    <div id="menu"></div>
  </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>

</body>
</html>
